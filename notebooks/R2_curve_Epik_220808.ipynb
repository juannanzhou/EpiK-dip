{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3c8288-f9c7-4a82-85cd-9af831755acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f3a2f3-9f4d-4c6a-a60e-194c428abb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import os\n",
    "import GPUtil\n",
    "import importlib\n",
    "\n",
    "def sgpu():\n",
    "    GPUtil.showUtilization()\n",
    "\n",
    "def rl(module):\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f62c83d-afbd-437e-8092-fbf352e388c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "sgpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6e52c0-7f3e-444b-9a93-73866acba381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26c5c81-59bd-4b6c-8f05-35718960fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EpiK.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4ff720-37a3-4cfd-a171-b727c829e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs = 8; output device = 0\n"
     ]
    }
   ],
   "source": [
    "output_device = 0\n",
    "n_devices = torch.cuda.device_count()\n",
    "models.set_params(output_device, n_devices)\n",
    "print(\"number of GPUs = {}; output device = {}\".\n",
    "      format(n_devices, torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e266f6d1-6a6f-45b4-bad3-e46ef9f065ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EpiK.functions import get_data, get_envs, set_data_path\n",
    "set_data_path(\"../matsui_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd9fbf2-6d86-4bd0-8969-92892866ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sizes\n",
    "props = [.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0335aa4d-a24c-442f-8fc7-dd775e15bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_point sizes\n",
    "partitions = [2, 2, 2, 2, 4, 4, 4, 4, 16, 32, 64, 120]\n",
    "pd.DataFrame({\"props\":props, \"partitions\":partitions}).to_csv(\"partition_sizes.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba7527b-8071-4486-a333-99346661d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_sizes = pd.read_csv(\"partition_sizes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b19d0-bc0d-4b11-bc08-a0f498eb8459",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026f761f-0a47-436d-9277-5cc343934c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_list = get_envs()\n",
    "env = env_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab6db51-a8bf-402c-8284-61ea0b9bc1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../EpiK/functions.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  geno_t = torch.tensor(geno_t, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "geno_t, pheno = get_data(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef14765-c39d-4591-837c-3c5cd47e53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_sub = np.where(np.array(pheno.pheno < -0.6) == False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565c048-4940-44f3-8248-bc5cd31466ef",
   "metadata": {},
   "source": [
    "### Loops to get R2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6224528-799c-4650-addb-4919921c304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EpiK.functions\n",
    "rl(EpiK.functions)\n",
    "from EpiK.functions import train_model_cv\n",
    "\n",
    "EpiK.functions.output_device = output_device\n",
    "EpiK.functions.n_devices = n_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114aa8de-d31a-4615-b164-00ac346995ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/48018959/ipykernel_39225/3682515763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r2s_epik.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(\"r2s_epik.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4c53e5-3571-41a7-8feb-78bc26506ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EpiK.kernels import DiKernel\n",
    "ker = DiKernel()\n",
    "ker.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "ker.raw_eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfdfad5e-e077-4d80-a5bf-67deb65f1993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training GP model using CV\n",
      "working on iteration 0\n",
      "working on iteration 10\n",
      "working on iteration 20\n",
      "working on iteration 30\n",
      "working on iteration 40\n"
     ]
    }
   ],
   "source": [
    "i = 11\n",
    "np.random.seed(100)\n",
    "train_size = np.round(props[i]*len(inds_sub)).astype('int')\n",
    "sub = np.random.choice(inds_sub, train_size)\n",
    "sub_t = np.random.choice(list(set(inds_sub).difference(sub)), 2000)\n",
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]), dtype=torch.float32)\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]), dtype=torch.float32)\n",
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)\n",
    "\n",
    "# train model\n",
    "print(\"training GP model using CV\")\n",
    "ker, likelihood = train_model_cv(ker, train_x, train_y, 50, .1)\n",
    "\n",
    "\n",
    "# make predictions - build model\n",
    "torch.cuda.empty_cache()\n",
    "model = models.ExactGPModel(train_x, train_y, likelihood, ker).to(output_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e2e2c-87f8-4f79-aa4d-5e68bd3288a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partition_size = partition_sizes.partitions[i]\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "with gpytorch.beta_features.checkpoint_kernel(train_x.shape[0]//int(partition_size)):\n",
    "    f_preds = model(test_x)\n",
    "\n",
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()\n",
    "r2_score = r2(y_test, f_mean)                \n",
    "results.iloc[i, 2] = r2_score\n",
    "\n",
    "results.to_csv(\"r2s_epik_220809.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d421a-de0b-4fa4-b4b7-9e62c8df79b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6922c4-0b5d-4429-8f6f-38fd997eea88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30575e-8d1c-482a-9677-57d2a60acc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6264e78-683b-4bed-9da7-b0510f1f552d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on training data proportion = 0.01\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.05\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.1\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.2\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.3\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.4\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.5\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.6\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.7\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.8\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.9\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.99\n",
      "no r2_score recorded, proceeding to calculate\n",
      "training GP model using CV\n",
      "working on iteration 0\n",
      "working on iteration 10\n",
      "working on iteration 20\n",
      "working on iteration 30\n",
      "working on iteration 40\n",
      "try doing inference under partition size = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py:102: NumericalWarning: NaNs encountered in preconditioner computation. Attempting to continue without preconditioning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 105\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 110\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 115\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 120\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 125\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 130\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 135\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 140\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 145\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 150\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 155\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 160\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 165\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 170\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 175\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 180\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 185\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 190\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 195\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 200\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 205\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 210\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 215\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 220\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 225\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 230\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 235\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 240\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 245\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 250\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 255\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 260\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 265\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 270\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 275\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 280\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 285\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 290\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 295\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 300\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 305\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 310\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 315\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 320\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 325\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 330\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 335\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 340\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 345\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 350\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 355\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 360\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 365\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 370\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 375\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 380\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 385\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 390\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 395\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 400\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 405\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 410\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 415\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 420\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 425\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 430\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 435\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 440\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 445\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 450\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 455\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 460\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 465\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 470\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 475\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 480\n",
      "failed on current partition_size, increasing by 5\n",
      "try doing inference under partition size = 485\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(props)):\n",
    "    \n",
    "    print(\"working on training data proportion = {}\".format(props[i]))\n",
    "    \n",
    "    if results.iloc[i].r2 != 0.:\n",
    "        print(\"r2_score found, skipping to next\")\n",
    "    \n",
    "    else:\n",
    "        print(\"no r2_score recorded, proceeding to calculate\")\n",
    "        np.random.seed(100)\n",
    "        train_size = np.round(props[i]*len(inds_sub)).astype('int')\n",
    "        sub = np.random.choice(inds_sub, train_size)\n",
    "        sub_t = np.random.choice(list(set(inds_sub).difference(sub)), 4000)\n",
    "        train_x = geno_t[sub]\n",
    "        train_y = torch.tensor(np.array(pheno.pheno[sub]), dtype=torch.float32)\n",
    "        test_x = geno_t[sub_t]\n",
    "        test_y = torch.tensor(np.array(pheno.pheno[sub_t]), dtype=torch.float32)\n",
    "        train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "        test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "        train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "        test_x, test_y = test_x.to(output_device), test_y.to(output_device)\n",
    "\n",
    "        # train model\n",
    "        print(\"training GP model using CV\")\n",
    "        ker, likelihood = train_model_cv(ker, train_x, train_y, 50, .1)\n",
    "        \n",
    "\n",
    "        # make predictions - build model\n",
    "        torch.cuda.empty_cache()\n",
    "        model = models.ExactGPModel(train_x, train_y, likelihood, ker).to(output_device)\n",
    "\n",
    "        # make predictions - loop to increase partition_size until passes\n",
    "        loop = True\n",
    "        while loop:\n",
    "            try: \n",
    "                partition_size = partition_sizes.iloc[i, 1]\n",
    "                print(\"try doing inference under partition size = {}\".format(partition_size))\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()                \n",
    "\n",
    "                model.eval()\n",
    "                likelihood.eval()\n",
    "                with gpytorch.beta_features.checkpoint_kernel(train_x.shape[0]//int(partition_size)):\n",
    "                    f_preds = model(test_x)\n",
    "                    \n",
    "                f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "                y_test = test_y.detach().cpu().numpy()\n",
    "                r2_score = r2(y_test, f_mean)                \n",
    "                results.iloc[i, 2] = r2_score\n",
    "                loop = False            \n",
    "\n",
    "            except: \n",
    "                print(\"failed on current partition_size, increasing by 5\")\n",
    "                partition_sizes.iloc[i, 1] = partition_sizes.iloc[i,1] + 5\n",
    "                partition_sizes.to_csv(\"partition_sizes.csv\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad320ce1-ca6a-465b-8413-548a63846340",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"r2_epik.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
