{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1363c3ae-64d7-4f58-b7fe-b99fae7ff6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 96% |\n",
      "|  1 |  0% | 81% |\n",
      "|  2 |  0% | 81% |\n",
      "|  3 |  0% | 81% |\n",
      "|  4 |  0% | 81% |\n",
      "|  5 |  0% | 81% |\n",
      "|  6 |  0% | 81% |\n",
      "|  7 |  0% | 81% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bff7c28-b37e-424e-95d1-1035f03fd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ae9952-691f-4759-9a78-8b53d20e5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360d08db-7d78-44c8-84e6-db093a078f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae487b32-a916-4129-87b8-0d8e02eb09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9519491-2f40-4abd-904f-f98f9640b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bcfbf4-b405-476e-ac21-df6136e1569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"96ghpptzvf-4/SData2/CoCl2_geno.txt\", sep='\\t', nrows=5, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31202a99-ab1b-421b-8a9d-cbe7d33b876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d9b4da-de21-45cf-8d16-dd4362aa0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.load('matsui_geno_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9811fd-b94c-441b-8775-b4e8b80d4145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geno_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33129b2f-7814-4432-901d-78b7adf9bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.transpose(geno_t, 0, 1)\n",
    "N, L = geno_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4001429-b8b3-46e7-967a-c1a5b0219194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(\"96ghpptzvf-4/SData6/CoCl2_pheno.txt\", sep='\\t', engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1eea171-8613-405f-afeb-2f617b20b70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pheno</th>\n",
       "      <th>MATa</th>\n",
       "      <th>MATalpha</th>\n",
       "      <th>geno</th>\n",
       "      <th>qnorm</th>\n",
       "      <th>MATa_mid</th>\n",
       "      <th>MATalpha_mid</th>\n",
       "      <th>midparent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021705</td>\n",
       "      <td>y39_A012</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A012</td>\n",
       "      <td>-0.021147</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.131384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.184045</td>\n",
       "      <td>y39_A02</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A02</td>\n",
       "      <td>-0.924553</td>\n",
       "      <td>-0.286352</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.311561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.133887</td>\n",
       "      <td>y39_A03</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A03</td>\n",
       "      <td>-0.640047</td>\n",
       "      <td>-0.896266</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.616517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021991</td>\n",
       "      <td>y39_A04</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A04</td>\n",
       "      <td>-0.022688</td>\n",
       "      <td>0.593958</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>0.128595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088438</td>\n",
       "      <td>y39_A05</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A05</td>\n",
       "      <td>0.574957</td>\n",
       "      <td>0.576434</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>0.119833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pheno      MATa    MATalpha                 geno     qnorm  MATa_mid  \\\n",
       "0 -0.021705  y39_A012  BYa_1C_A10  BYa_1C_A10.y39_A012 -0.021147  0.074002   \n",
       "1 -0.184045   y39_A02  BYa_1C_A10   BYa_1C_A10.y39_A02 -0.924553 -0.286352   \n",
       "2 -0.133887   y39_A03  BYa_1C_A10   BYa_1C_A10.y39_A03 -0.640047 -0.896266   \n",
       "3 -0.021991   y39_A04  BYa_1C_A10   BYa_1C_A10.y39_A04 -0.022688  0.593958   \n",
       "4  0.088438   y39_A05  BYa_1C_A10   BYa_1C_A10.y39_A05  0.574957  0.576434   \n",
       "\n",
       "   MATalpha_mid  midparent  \n",
       "0     -0.336769  -0.131384  \n",
       "1     -0.336769  -0.311561  \n",
       "2     -0.336769  -0.616517  \n",
       "3     -0.336769   0.128595  \n",
       "4     -0.336769   0.119833  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935e7bbc-7f10-4b47-866b-8ef420348720",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.set_index('geno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96895ce0-fff1-4b90-8c38-7732f4e20df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.loc[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b72cd-c626-4d8d-9037-c661d48fa554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ea0c7-d313-4733-a2ea-51ac780df663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaed242-4daf-4e58-b33a-ad98d0aa8a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9364a5-0570-4596-9248-d59683e9f2a3",
   "metadata": {},
   "source": [
    "### Test Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5870ec2b-d895-4641-ac29-1a865cba467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.random.choice(range(N), 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa98000-8d2f-43a2-9ee7-9c2388e44764",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_t = np.random.choice(list(set(range(N)).difference(sub)), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb991116-b69a-482c-ad83-2714b4daf6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]))\n",
    "\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "438068fc-6331-4d78-a3af-74be9d40a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "output_device = torch.device('cuda:0')\n",
    "\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19b3b9c7-1199-4448-85d0-547846392012",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ad59b9e-48bb-4003-a44c-7e53ef9282e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 8 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44181f62-241d-4c9d-aea3-b95993fdd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(geno1, geno2):\n",
    "  \"\"\"build distance tensor between two sets of genotypes\n",
    "  geno1, geno2: n x L, m x L torch tensors\n",
    "  \n",
    "  \"\"\"\n",
    "  geno1_h0 = 1.*(geno1 == 0.)\n",
    "  geno1_h1 = 1.*(geno1 == 2.)\n",
    "  geno2_h0 = 1.*(geno2 == 0.)\n",
    "  geno2_h1 = 1.*(geno2 == 2.)\n",
    "  S1 = torch.matmul(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "  S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "  D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "  D1 = L - S1 - S2 - D2\n",
    "\n",
    "  return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e30182-71db-4914-a232-6f163873c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(log_lda, log_eta, dvec):\n",
    "    \"\"\"\n",
    "    log_lda, log_eta -- torch tensors\n",
    "    dvec -- 4 x n x m torch tensor\n",
    "    \"\"\"\n",
    "    lda = torch.exp(log_lda)\n",
    "    eta = torch.exp(log_eta)\n",
    "    return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "          *((1 - lda + eta)**dvec[3])\n",
    "          *((1 + eta)**(dvec[0] - L/2)) \n",
    "          * (1-eta)**dvec[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f88ae02-6587-4718-9a84-33af63e3e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "class DiKernel(gpytorch.kernels.Kernel):\n",
    "  \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "  is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "  def __init__(self, \n",
    "                lda_prior=None, lda_constraint=None, \n",
    "                eta_prior=None, eta_constraint=None,\n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # register the raw parameter\n",
    "      self.register_parameter(\n",
    "          name='raw_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      self.register_parameter(\n",
    "          name='raw_eta', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      # set the parameter constraint to be positive, when nothing is specified\n",
    "      if lda_constraint is None:\n",
    "          lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      if eta_constraint is None:\n",
    "          eta_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      # register the constraint\n",
    "      self.register_constraint(\"raw_lda\", lda_constraint)\n",
    "      self.register_constraint(\"raw_eta\", eta_constraint)\n",
    "\n",
    "      \n",
    "  # now set up the 'actual' paramter\n",
    "  @property\n",
    "  def lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_lda_constraint.transform(self.raw_lda)\n",
    "\n",
    "  @property\n",
    "  def eta(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_eta_constraint.transform(self.raw_eta)\n",
    "\n",
    "  @lda.setter\n",
    "  def lda(self, value):\n",
    "      return self._set_lda(value)\n",
    "\n",
    "  @eta.setter\n",
    "  def eta(self, value):\n",
    "      return self._set_eta(value)\n",
    "\n",
    "  def forward(self, x1, x2, **params):\n",
    "    diff = d(x1, x2)\n",
    "    return k(lda, eta, diff)\n",
    "#     return k(self.lda, self.eta, diff)\n",
    "#     return self.eta*diff[0]\n",
    "#     dvec = diff\n",
    "#     log_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "#     log_eta = torch.nn.Parameter(torch.tensor(-12.))\n",
    "#     lda = torch.exp(log_lda)\n",
    "#     eta = torch.exp(log_eta)\n",
    "    \n",
    "#     return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "#     *((1 - lda + eta)**dvec[3])\n",
    "#     *((1 + eta)**(dvec[0] - L/2)) \n",
    "#     * (1-eta)**dvec[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63bb2e51-1a27-41b7-bb5c-dd0b8f325381",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cd0a785-cec9-4767-872d-424d9fce9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            DiKernel(), device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d434c224-f533-4554-a8ea-d8a31190316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "#   def __init__(self, train_x, train_y, likelihood):\n",
    "#     super().__init__(train_x, train_y, likelihood)\n",
    "#     self.mean_module = gpytorch.means.ConstantMean()\n",
    "#     self.covar_module = DiKernel()\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     mean_x = self.mean_module(x)\n",
    "#     covar_x = self.covar_module(x)\n",
    "#     return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1af0f525-d353-4580-bac7-408c5f4fa75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = DiGPModel(train_x, train_y, likelihood)\n",
    "model = model.double().to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75c9cdd3-8648-4823-ad80-1e0aec03e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.covar_module.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "model.covar_module.raw_eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5ef61c0-f720-44a6-a33e-bce3f12d9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8d4de26-aa47-4492-885f-aee64740f1ce",
   "metadata": {
    "id": "wgQmFW5a7U43"
   },
   "outputs": [],
   "source": [
    "test_x = test_x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bcdc91d-829b-456a-8fc8-35609411506a",
   "metadata": {
    "id": "vm4QV20LMs4O"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.46 GiB (GPU 0; 79.35 GiB total capacity; 73.19 GiB already allocated; 3.00 GiB free; 74.49 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/24797895/ipykernel_60746/3415707808.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# Make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_eval_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mpredictive_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictive_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# Reshape predictive mean to match the appropriate event shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    261\u001b[0m         return (\n\u001b[1;32m    262\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         )\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_predictive_covar\u001b[0;34m(self, test_test_covar, test_train_covar)\u001b[0m\n\u001b[1;32m    306\u001b[0m             )\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_test_caches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mtrain_train_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_covariance_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mtrain_train_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_covariance_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         LazyTensor from the computation graph.)\n\u001b[1;32m   1028\u001b[0m         \"\"\"\n\u001b[0;32m-> 1029\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mClones\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLazyTensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcreates\u001b[0m \u001b[0mclones\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"\"\"\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mClones\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLazyTensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcreates\u001b[0m \u001b[0mclones\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"\"\"\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mClones\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLazyTensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcreates\u001b[0m \u001b[0mclones\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"\"\"\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mClones\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLazyTensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcreates\u001b[0m \u001b[0mclones\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"\"\"\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clone\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.46 GiB (GPU 0; 79.35 GiB total capacity; 73.19 GiB already allocated; 3.00 GiB free; 74.49 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "f_preds = model(test_x)\n",
    "y_preds = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f0edfe2-78bd-4334-b685-1d07ac33ac46",
   "metadata": {
    "id": "OGZwj3R1NV9z"
   },
   "outputs": [],
   "source": [
    "f_mean = f_preds.mean.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d735461-12a0-4d11-8b9a-15e7c0f3c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': lda},\n",
    "    {'params': eta}\n",
    "], lr = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b283e7d-be3d-42a9-b9f6-5a14600bbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34e47ab2-9155-424e-9bdf-5a58317493b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:234: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.sum(mul_storage, -2, keepdim=True, out=alpha)\n"
     ]
    }
   ],
   "source": [
    "loss = -mll(output, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec0e2171-081a-43c6-b80f-61b62e2e4a1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.35 GiB (GPU 0; 79.35 GiB total capacity; 75.63 GiB already allocated; 1.76 GiB free; 75.73 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/24797895/ipykernel_54048/2859123600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.35 GiB (GPU 0; 79.35 GiB total capacity; 75.63 GiB already allocated; 1.76 GiB free; 75.73 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72e62f-eb13-49d1-9ac7-7962fdd9997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2118b33-435c-4853-882b-ce31b274aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "47d4e30a-cd9c-478b-aa6b-b8756f061ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_x,\n",
    "          train_y,\n",
    "          n_devices,\n",
    "          output_device,\n",
    "          checkpoint_size,\n",
    "          preconditioner_size,\n",
    "          n_training_iter,\n",
    "          lr\n",
    "):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': model.parameters()},\n",
    "        {'params': lda},\n",
    "        {'params': eta}\n",
    "    ], lr = .05)\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(n_training_iter):\n",
    "      if i%20==0:\n",
    "        print(i)\n",
    "      else: pass\n",
    "      # Zero gradients from previous iteration\n",
    "      optimizer.zero_grad()\n",
    "      # Output from model\n",
    "      output = model(train_x)\n",
    "      # Calc loss and backprop gradients\n",
    "      loss = -mll(output, train_y)\n",
    "      loss.backward()\n",
    "      losses.append(loss.item())    \n",
    "      optimizer.step()\n",
    "      del loss\n",
    "    return losses\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#     with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "#          gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "\n",
    "#         def closure():\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(train_x)\n",
    "#             loss = -mll(output, train_y)\n",
    "#             return loss\n",
    "\n",
    "#         loss = closure()\n",
    "#         loss.backward()\n",
    "\n",
    "#         for i in range(n_training_iter):\n",
    "#             options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "#             loss, _, _, _, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "#             print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "#                 i + 1, n_training_iter, loss.item(),\n",
    "#                 model.covar_module.module.base_kernel.lengthscale.item(),\n",
    "#                 model.likelihood.noise.item()\n",
    "#             ))\n",
    "\n",
    "#             if fail:\n",
    "#                 print('Convergence reached!')\n",
    "#                 break\n",
    "\n",
    "#     print(f\"Finished training on {train_x.size(0)} data points using {n_devices} GPUs.\")\n",
    "#     return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "39813038-7c65-4d34-a177-8f01d5feb080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Float but expected Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/24771440/ipykernel_162426/948882100.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m losses = train(model,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/24771440/ipykernel_162426/3938071116.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_x, train_y, n_devices, output_device, checkpoint_size, preconditioner_size, n_training_iter, lr)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;31m# Calc loss and backprop gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvQuadLogDet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         inv_quad_term, logdet_term = func(\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_quad_log_det.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_logdet_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0msolves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         return utils.linear_cg(\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py\u001b[0m in \u001b[0;36mlinear_cg\u001b[0;34m(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# residual: residual_{0} = b_vec - lhs x_{0}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmatmul_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_guess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madded_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Float but expected Double"
     ]
    }
   ],
   "source": [
    "losses = train(model,\n",
    "    train_x,\n",
    "    train_y,\n",
    "    n_devices,\n",
    "    output_device,\n",
    "    checkpoint_size,\n",
    "    preconditioner_size,\n",
    "    n_training_iter=100,\n",
    "    lr=.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf7ff9-3bc6-4b08-bda6-b03ce18185b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c01301-9b96-4554-89a6-50a2892e2018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe7de4-1726-4761-8703-fd6103a0b940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2727c-913a-45f5-8f42-d86505db509a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbf9b4-a43d-4c44-8297-202bcd54cf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2712df6a-ba76-4104-965e-008f91a5c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4 -- Kernel partition size: 0\n",
      "RuntimeError: Found dtype Float but expected Double\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py:102: NumericalWarning: NaNs encountered in preconditioner computation. Attempting to continue without preconditioning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4 -- Kernel partition size: 5000\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 2500\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 1250\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 625\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 313\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 157\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 79\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 40\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 20\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 10\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 5\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 3\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def find_best_gpu_setting(train_x,\n",
    "                          train_y,\n",
    "                          n_devices,\n",
    "                          output_device,\n",
    "                          preconditioner_size\n",
    "):\n",
    "    N = train_x.size(0)\n",
    "\n",
    "    # Find the optimum partition/checkpoint size by decreasing in powers of 2\n",
    "    # Start with no partitioning (size = 0)\n",
    "    settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]\n",
    "\n",
    "    for checkpoint_size in settings:\n",
    "        print('Number of devices: {} -- Kernel partition size: {}'.format(n_devices, checkpoint_size))\n",
    "        try:\n",
    "            # Try a full forward and backward pass with this setting to check memory usage\n",
    "            _, _ = train(model, train_x, train_y,\n",
    "                         n_devices=n_devices, output_device=output_device,\n",
    "                         checkpoint_size=checkpoint_size,\n",
    "                         preconditioner_size=preconditioner_size, n_training_iter=1, lr=0.05)\n",
    "\n",
    "            # when successful, break out of for-loop and jump to finally block\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            print('RuntimeError: {}'.format(e))\n",
    "        except AttributeError as e:\n",
    "            print('AttributeError: {}'.format(e))\n",
    "        finally:\n",
    "            # handle CUDA OOM error\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return checkpoint_size\n",
    "\n",
    "# Set a large enough preconditioner size to reduce the number of CG iterations run\n",
    "preconditioner_size = 100\n",
    "checkpoint_size = find_best_gpu_setting(train_x, train_y,\n",
    "                                        n_devices=n_devices,\n",
    "                                        output_device=output_device,\n",
    "                                        preconditioner_size=preconditioner_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2255b-7636-4bd3-9b8a-47bdef4f2948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
