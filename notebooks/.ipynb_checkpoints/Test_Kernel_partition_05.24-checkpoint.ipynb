{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61febdc1-bb02-40b1-a5db-d861568b787e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df23c08b-7fef-42cd-9d86-a33d1a862081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def rl():\n",
    "    importlib.reload(Di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db4d4b5-112f-4432-b9e2-dfa948d538bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ec58e7-4447-4f3e-bf5f-ed51affca87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6e272d-9d05-4cfe-912d-a328c097ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f309085-b33f-4f85-bef7-26b8f811d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_file_list = []\n",
    "for path, currentDirectory, files in os.walk(\"96ghpptzvf-4/SData2/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"geno.txt\"):\n",
    "            geno_file_list.append(file)\n",
    "\n",
    "geno_file_list = list(set(geno_file_list))\n",
    "\n",
    "env_list = [file.split('_')[0] for file in geno_file_list]\n",
    "\n",
    "env_list = sorted(env_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a217d511-3dfc-4ec0-b62a-bf7f2e81c1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaCl\n"
     ]
    }
   ],
   "source": [
    "env = env_list[5]\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232f0e16-2fab-476c-a9ce-af777f066603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"96ghpptzvf-4/SData2/\"+ env + \"_geno.txt\", sep='\\t', nrows=5, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9b3d44-db85-47bd-850b-d4b4160be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea5557b-a26d-453d-aae4-e45be587f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NaCl_matsui_geno_t.pt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env + '_matsui_geno_t.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d9ea16-ec8c-4142-a02a-2c46fe7ae643",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.load(env + '_matsui_geno_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfde8729-0f01-4ac5-a558-9ab90be05613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geno_t = torch.transpose(geno_t, 0, 1)\n",
    "# N, L = geno_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78615deb-c2fd-4c9a-8d35-7757ae112f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use very small subset of loci\n",
    "\n",
    "geno_t = torch.transpose(geno_t, 0, 1)\n",
    "\n",
    "geno_t = geno_t[:,:10]\n",
    "\n",
    "N, L = geno_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5953bc-1441-4b15-9047-bc92c8153557",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(\"96ghpptzvf-4/SData6/\" + env + \"_pheno.txt\", sep='\\t', engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd03651-f9ce-47a9-bb6a-a8375ea5d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.set_index('geno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e4fc78-4a7f-457e-a57f-57a3d677f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.loc[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f19cac8-653a-4206-a887-14376ee31dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pheno.pheno)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82f55c-a8ec-42c1-8108-a6de0753b118",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1059cb8-6b75-4dd4-af5b-c791f1537f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 8 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1a501f-5cb9-4e04-b72c-ff26fc9f5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfff37-e18c-4095-933f-92e27ee7e05f",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d16029-a360-4b5f-aa0d-01fd19adfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_sub = np.where(np.array(pheno.pheno < -0.6) == False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a0be55d-c922-40f3-babe-ec6c2892dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44bfd463-8723-4d71-b6b2-4b33ad425a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.random.choice(inds_sub, 50000)\n",
    "\n",
    "sub_t = np.random.choice(list(set(inds_sub).difference(sub)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5d3767-89f5-4e30-a005-8ca73d024960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]), dtype=torch.float32)\n",
    "\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ff3840c-1f74-47f9-932b-70dfc5c5d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32a492-76eb-4689-85ff-163fcdda4122",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a24b0166-d4b7-4ee4-942d-01cd6430db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(geno1, geno2):\n",
    "    \"\"\"build distance tensor between two sets of genotypes\n",
    "    geno1, geno2: n x L, m x L torch tensors\n",
    "\n",
    "    \"\"\"\n",
    "    geno1_h0 = 1.*(geno1 == 0.)\n",
    "    geno1_h1 = 1.*(geno1 == 2.)\n",
    "    geno2_h0 = 1.*(geno2 == 0.)\n",
    "    geno2_h1 = 1.*(geno2 == 2.)\n",
    "    S1 = torch.matmul(geno1%2., torch.transpose(geno2%2., 0, 1))\n",
    "    S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "    D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "    D1 = L - S1 - S2 - D2\n",
    "\n",
    "    return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d01992-29f1-446e-8873-c5442ffe0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def d(geno1, geno2):\n",
    "#     \"\"\"build distance tensor between two sets of genotypes\n",
    "#     geno1, geno2: n x L, m x L torch tensors\n",
    "\n",
    "#     \"\"\"\n",
    "# #     geno1_h0 = 1.*(geno1 == 0.)\n",
    "# #     geno1_h1 = 1.*(geno1 == 2.)\n",
    "# #     geno2_h0 = 1.*(geno2 == 0.)\n",
    "# #     geno2_h1 = 1.*(geno2 == 2.)\n",
    "#     S1 = torch.matmul(geno1%2., torch.transpose(geno2%2., 0, 1))\n",
    "#     #   S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "#     #         + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "#     #   D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "#     #         + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "#     S2 = S1\n",
    "#     D2 = S1\n",
    "#     D1 = L - S1 - S2 - D2\n",
    "\n",
    "#     return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f7995e8-94d8-4f9b-b3fc-373ff8afee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(log_lda, log_eta, dvec):\n",
    "    \"\"\"\n",
    "    log_lda, log_eta -- torch tensors\n",
    "    dvec -- 4 x n x m torch tensor\n",
    "    \"\"\"\n",
    "    lda = torch.exp(log_lda)\n",
    "    eta = torch.exp(log_eta)\n",
    "    return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "          *((1 - lda + eta)**dvec[3])\n",
    "          *((1 + eta)**(dvec[0] - L/2)) \n",
    "          * (1-eta)**dvec[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dcf297b-3e13-4654-970f-8f63e85c53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "\n",
    "class DiKernel(gpytorch.kernels.Kernel):\n",
    "  \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "  is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "  def __init__(self, \n",
    "                lda_prior=None, lda_constraint=None, \n",
    "                eta_prior=None, eta_constraint=None,\n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # register the raw parameter\n",
    "      self.register_parameter(\n",
    "          name='raw_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      self.register_parameter(\n",
    "          name='raw_eta', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      # set the parameter constraint to be positive, when nothing is specified\n",
    "      if lda_constraint is None:\n",
    "          lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      if eta_constraint is None:\n",
    "          eta_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      # register the constraint\n",
    "      self.register_constraint(\"raw_lda\", lda_constraint)\n",
    "      self.register_constraint(\"raw_eta\", eta_constraint)\n",
    "\n",
    "      \n",
    "  # now set up the 'actual' paramter\n",
    "  @property\n",
    "  def lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_lda_constraint.transform(self.raw_lda)\n",
    "\n",
    "  @property\n",
    "  def eta(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_eta_constraint.transform(self.raw_eta)\n",
    "\n",
    "  @lda.setter\n",
    "  def lda(self, value):\n",
    "      return self._set_lda(value)\n",
    "\n",
    "  @eta.setter\n",
    "  def eta(self, value):\n",
    "      return self._set_eta(value)\n",
    "\n",
    "  def forward(self, x1, x2, diag=False, **params):\n",
    "      diff = d(x1, x2)\n",
    "      K = k(self.lda, self.eta, diff)\n",
    "      if diag:\n",
    "        K = K[0]\n",
    "      return K\n",
    "      \n",
    "\n",
    "    \n",
    "class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            DiKernel(), device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa7388b1-b770-4061-8602-762846d4fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinKernel(gpytorch.kernels.Kernel):\n",
    "  \"\"\"Additive kernel\"\"\"\n",
    "\n",
    "  is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "  def __init__(self, \n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "  def forward(self, x1, x2, diag=False, **params):\n",
    "      if diag:\n",
    "        K = K[0]    \n",
    "      return torch.matmul(x1, x2.T)\n",
    "\n",
    "\n",
    "class LinGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            LinKernel(), device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c2947e6-970a-40b5-92ec-2a5813567fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel2(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01faa548-a2ff-48ff-8672-515fdf1f6939",
   "metadata": {},
   "source": [
    "### Test linear kernel partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2e61c6d-2820-4353-88c4-7d24fe2c1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "model = LinGPModel(train_x, train_y, likelihood)\n",
    "model = model.to(output_device).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a928e845-1b8e-4235-b6ba-35f726dcf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), .02)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62536373-cbe8-400e-a6b6-c89f94ad1e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([50000]). Got size torch.Size([50000, 50000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_134450/2496959805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Make predictions on a small number of test points to get the test time caches computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mf_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# Make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_eval_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mpredictive_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictive_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# Reshape predictive mean to match the appropriate event shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         return (\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_predictive_mean\u001b[0;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# GP, and using addmv requires you to delazify test_train_covar, which is obviously a huge no-no!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_train_covar\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mmean_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mtrain_labels_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mmean_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_train_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_test_caches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_matmul\u001b[0;34m(self, right_tensor, left_tensor)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvMatmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_matmul.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, has_left, *args)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_tensor\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msolves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_matmul.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(lazy_tsr, rhs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpreconditioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv_matmul_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_inv_matmul_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mon\u001b[0m \u001b[0mx\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \"\"\"\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mbase_precond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase_precond\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_preconditioner_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/pivoted_cholesky.py\u001b[0m in \u001b[0;36mpivoted_cholesky\u001b[0;34m(matrix, max_iter, error_tol)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# LazyTensor.diag() operates in batch mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmatrix_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_approx_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Make sure max_iter isn't bigger than the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_approx_diag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdiagonal\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdiagonals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cholesky\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mexpected_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    264\u001b[0m                     \u001b[0;34m\"The kernel {} is not equipped to handle and diag. Expected size {}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;34m\"Got size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([50000]). Got size torch.Size([50000, 50000])"
     ]
    }
   ],
   "source": [
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(20):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05945-e264-4ef8-986e-16ae38cc5189",
   "metadata": {},
   "source": [
    "### Test DI kernel partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd74c61a-e3e9-4bb2-9d85-123e949c0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "model = DiGPModel(train_x, train_y, likelihood)\n",
    "model.covar_module.module.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "model.covar_module.module.raw_eta = torch.nn.Parameter(torch.tensor(-12.))\n",
    "model = model.to(output_device).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6acb469f-707d-4984-b65e-313de227cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), .02)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69d7b4bf-dec2-49e3-8887-0d9dcc7c5ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# with gpytorch.beta_features.checkpoint_kernel(0):\n",
    "\n",
    "#     output = model(train_x)\n",
    "#     loss = -mll(output, train_y)\n",
    "#     loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a90b5681-2c45-404d-8973-bce43e87fd75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 18.63 GiB (GPU 0; 79.35 GiB total capacity; 66.92 GiB already allocated; 10.61 GiB free; 66.93 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_81500/2496959805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Make predictions on a small number of test points to get the test time caches computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mf_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# Make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_eval_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mpredictive_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictive_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# Reshape predictive mean to match the appropriate event shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         return (\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_predictive_mean\u001b[0;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# GP, and using addmv requires you to delazify test_train_covar, which is obviously a huge no-no!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_train_covar\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mmean_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mtrain_labels_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mmean_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_train_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_test_caches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_matmul\u001b[0;34m(self, right_tensor, left_tensor)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvMatmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_matmul.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, has_left, *args)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_tensor\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msolves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_matmul.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(lazy_tsr, rhs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpreconditioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv_matmul_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_inv_matmul_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mon\u001b[0m \u001b[0mx\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \"\"\"\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mbase_precond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase_precond\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_preconditioner_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/pivoted_cholesky.py\u001b[0m in \u001b[0;36mpivoted_cholesky\u001b[0;34m(matrix, max_iter, error_tol)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# LazyTensor.diag() operates in batch mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmatrix_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_approx_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Make sure max_iter isn't bigger than the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_approx_diag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdiagonal\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdiagonals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cholesky\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         res = super(Kernel, self.kernel).__call__(\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_81500/934878869.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_81500/1824100744.py\u001b[0m in \u001b[0;36md\u001b[0;34m(geno1, geno2)\u001b[0m\n\u001b[1;32m     13\u001b[0m     D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n\u001b[1;32m     14\u001b[0m         + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mD1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mS1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mS2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 18.63 GiB (GPU 0; 79.35 GiB total capacity; 66.92 GiB already allocated; 10.61 GiB free; 66.93 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(20):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0d0a002-469c-4016-9160-c97da36e1db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 87% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "929013f0-505b-4c81-a79b-cbdf2a75b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_size = 10000\n",
    "preconditioner_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e6e9cd0-cb48-4647-980b-c1d2e5f93fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "#      gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "#     output = model(train_x)\n",
    "#     loss = -mll(output, train_y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd172ab0-afce-439e-b40f-3cd6cb47f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a2e01b9-c073-473f-883d-22b03c135404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.712284\n",
      "R2 = 0.587307\n",
      "mse = 0.003773\n"
     ]
    }
   ],
   "source": [
    "# epistatic\n",
    "figure(figsize=(5, 5), dpi=80)\n",
    "plt.plot(f_mean, y_test, 'o', alpha=.3)\n",
    "plt.show()\n",
    "print('r2 = %f'%pearsonr(f_mean, y_test)[0]**2)\n",
    "print('R2 = %f'%r2(y_test, f_mean))\n",
    "print('mse = %f'%mse(f_mean, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314e38d-4500-453b-b9cc-de1b39c196ea",
   "metadata": {},
   "source": [
    "### Test using gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d495350-a1e2-45de-bca7-66849605cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel2(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee6a5569-a0ac-43be-bf1e-cfb0dc662c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "model = DiGPModel2(train_x, train_y, likelihood)\n",
    "model = model.to(output_device).double()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), .02)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2f0b3f7-8159-40d1-9dcf-f31812492ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(1000):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "676990bc-f75e-4f84-ad7c-065e91ffb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c77459f-3aa5-44ec-8a2e-428fd0667c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = nan\n",
      "R2 = -0.103277\n",
      "mse = 0.006766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.4.1.cuda11/lib/python3.8/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "# epistatic\n",
    "figure(figsize=(5, 5), dpi=80)\n",
    "plt.plot(f_mean, y_test, 'o', alpha=.3)\n",
    "plt.show()\n",
    "print('r2 = %f'%pearsonr(f_mean, y_test)[0]**2)\n",
    "print('R2 = %f'%r2(y_test, f_mean))\n",
    "print('mse = %f'%mse(f_mean, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d676ee1b-ddd8-4968-a4e8-4912b27b29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), .02)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a85607a2-3910-48f7-8cac-57923009501a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:234: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.sum(mul_storage, -2, keepdim=True, out=alpha)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(100):\n",
    "\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
