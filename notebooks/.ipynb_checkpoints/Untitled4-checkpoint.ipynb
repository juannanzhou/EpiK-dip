{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bff7c28-b37e-424e-95d1-1035f03fd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ae9952-691f-4759-9a78-8b53d20e5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360d08db-7d78-44c8-84e6-db093a078f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae487b32-a916-4129-87b8-0d8e02eb09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9519491-2f40-4abd-904f-f98f9640b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5bcfbf4-b405-476e-ac21-df6136e1569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"96ghpptzvf-4/SData2/CoCl2_geno.txt\", sep='\\t', nrows=5, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31202a99-ab1b-421b-8a9d-cbe7d33b876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d9b4da-de21-45cf-8d16-dd4362aa0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.load('matsui_geno_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9811fd-b94c-441b-8775-b4e8b80d4145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geno_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33129b2f-7814-4432-901d-78b7adf9bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.transpose(geno_t, 0, 1)\n",
    "N, L = geno_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4001429-b8b3-46e7-967a-c1a5b0219194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(\"96ghpptzvf-4/SData6/CoCl2_pheno.txt\", sep='\\t', engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1eea171-8613-405f-afeb-2f617b20b70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pheno</th>\n",
       "      <th>MATa</th>\n",
       "      <th>MATalpha</th>\n",
       "      <th>geno</th>\n",
       "      <th>qnorm</th>\n",
       "      <th>MATa_mid</th>\n",
       "      <th>MATalpha_mid</th>\n",
       "      <th>midparent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021705</td>\n",
       "      <td>y39_A012</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A012</td>\n",
       "      <td>-0.021147</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.131384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.184045</td>\n",
       "      <td>y39_A02</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A02</td>\n",
       "      <td>-0.924553</td>\n",
       "      <td>-0.286352</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.311561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.133887</td>\n",
       "      <td>y39_A03</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A03</td>\n",
       "      <td>-0.640047</td>\n",
       "      <td>-0.896266</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.616517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021991</td>\n",
       "      <td>y39_A04</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A04</td>\n",
       "      <td>-0.022688</td>\n",
       "      <td>0.593958</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>0.128595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088438</td>\n",
       "      <td>y39_A05</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A05</td>\n",
       "      <td>0.574957</td>\n",
       "      <td>0.576434</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>0.119833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pheno      MATa    MATalpha                 geno     qnorm  MATa_mid  \\\n",
       "0 -0.021705  y39_A012  BYa_1C_A10  BYa_1C_A10.y39_A012 -0.021147  0.074002   \n",
       "1 -0.184045   y39_A02  BYa_1C_A10   BYa_1C_A10.y39_A02 -0.924553 -0.286352   \n",
       "2 -0.133887   y39_A03  BYa_1C_A10   BYa_1C_A10.y39_A03 -0.640047 -0.896266   \n",
       "3 -0.021991   y39_A04  BYa_1C_A10   BYa_1C_A10.y39_A04 -0.022688  0.593958   \n",
       "4  0.088438   y39_A05  BYa_1C_A10   BYa_1C_A10.y39_A05  0.574957  0.576434   \n",
       "\n",
       "   MATalpha_mid  midparent  \n",
       "0     -0.336769  -0.131384  \n",
       "1     -0.336769  -0.311561  \n",
       "2     -0.336769  -0.616517  \n",
       "3     -0.336769   0.128595  \n",
       "4     -0.336769   0.119833  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935e7bbc-7f10-4b47-866b-8ef420348720",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.set_index('geno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96895ce0-fff1-4b90-8c38-7732f4e20df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.loc[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b72cd-c626-4d8d-9037-c661d48fa554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ea0c7-d313-4733-a2ea-51ac780df663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaed242-4daf-4e58-b33a-ad98d0aa8a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9364a5-0570-4596-9248-d59683e9f2a3",
   "metadata": {},
   "source": [
    "### Test Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5870ec2b-d895-4641-ac29-1a865cba467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.random.choice(range(N), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "caa98000-8d2f-43a2-9ee7-9c2388e44764",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_t = np.random.choice(list(set(range(N)).difference(sub)), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bb991116-b69a-482c-ad83-2714b4daf6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]))\n",
    "\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "438068fc-6331-4d78-a3af-74be9d40a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "output_device = torch.device('cuda:0')\n",
    "\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19b3b9c7-1199-4448-85d0-547846392012",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ad59b9e-48bb-4003-a44c-7e53ef9282e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 4 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44181f62-241d-4c9d-aea3-b95993fdd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(geno1, geno2):\n",
    "  \"\"\"build distance tensor between two sets of genotypes\n",
    "  geno1, geno2: n x L, m x L torch tensors\n",
    "  \n",
    "  \"\"\"\n",
    "  geno1_h0 = 1.*(geno1 == 0.)\n",
    "  geno1_h1 = 1.*(geno1 == 2.)\n",
    "  geno2_h0 = 1.*(geno2 == 0.)\n",
    "  geno2_h1 = 1.*(geno2 == 2.)\n",
    "  S1 = torch.matmul(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "  S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "  D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "  D1 = L - S1 - S2 - D2\n",
    "\n",
    "  return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "34e30182-71db-4914-a232-6f163873c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(log_lda, log_eta, dvec):\n",
    "    \"\"\"\n",
    "    log_lda, log_eta -- torch tensors\n",
    "    dvec -- 4 x n x m torch tensor\n",
    "    \"\"\"\n",
    "    lda = torch.exp(log_lda)\n",
    "    eta = torch.exp(log_eta)\n",
    "    return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "          *((1 - lda + eta)**dvec[3])\n",
    "          *((1 + eta)**(dvec[0] - L/2)) \n",
    "          * (1-eta)**dvec[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5f88ae02-6587-4718-9a84-33af63e3e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "class DiKernel(gpytorch.kernels.Kernel):\n",
    "  \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "  is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "  def __init__(self, \n",
    "                lda_prior=None, lda_constraint=None, \n",
    "                eta_prior=None, eta_constraint=None,\n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # register the raw parameter\n",
    "      self.register_parameter(\n",
    "          name='raw_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      self.register_parameter(\n",
    "          name='raw_eta', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      # set the parameter constraint to be positive, when nothing is specified\n",
    "      if lda_constraint is None:\n",
    "          lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      if eta_constraint is None:\n",
    "          eta_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      # register the constraint\n",
    "      self.register_constraint(\"raw_lda\", lda_constraint)\n",
    "      self.register_constraint(\"raw_eta\", eta_constraint)\n",
    "\n",
    "      \n",
    "  # now set up the 'actual' paramter\n",
    "  @property\n",
    "  def lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_lda_constraint.transform(self.raw_lda)\n",
    "\n",
    "  @property\n",
    "  def eta(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_eta_constraint.transform(self.raw_eta)\n",
    "\n",
    "  @lda.setter\n",
    "  def lda(self, value):\n",
    "      return self._set_lda(value)\n",
    "\n",
    "  @eta.setter\n",
    "  def eta(self, value):\n",
    "      return self._set_eta(value)\n",
    "\n",
    "  def forward(self, x1, x2, **params):\n",
    "    diff = d(x1, x2)\n",
    "    return k(self.lda, self.eta, diff)\n",
    "    return diff[1]\n",
    "#     dvec = diff\n",
    "#     log_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "#     log_eta = torch.nn.Parameter(torch.tensor(-12.))\n",
    "#     lda = torch.exp(log_lda)\n",
    "#     eta = torch.exp(log_eta)\n",
    "    \n",
    "#     return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "#     *((1 - lda + eta)**dvec[3])\n",
    "#     *((1 + eta)**(dvec[0] - L/2)) \n",
    "#     * (1-eta)**dvec[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0cd0a785-cec9-4767-872d-424d9fce9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            DiKernel(), device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d434c224-f533-4554-a8ea-d8a31190316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = DiKernel()\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1af0f525-d353-4580-bac7-408c5f4fa75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = DiGPModel(train_x, train_y, likelihood)\n",
    "model = model.double().to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "75c9cdd3-8648-4823-ad80-1e0aec03e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.covar_module.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "model.covar_module.raw_eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e5ef61c0-f720-44a6-a33e-bce3f12d9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5b283e7d-be3d-42a9-b9f6-5a14600bbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "69660ca4-9045-466d-8daa-fca29a1623ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9289, 0.3216, 0.1868,  ..., 0.2355, 0.3019, 0.2670],\n",
       "        [0.3216, 0.7786, 0.2293,  ..., 0.2453, 0.2977, 0.2981],\n",
       "        [0.1868, 0.2293, 0.9006,  ..., 0.3006, 0.2139, 0.2622],\n",
       "        ...,\n",
       "        [0.2355, 0.2453, 0.3006,  ..., 0.9443, 0.2237, 0.2303],\n",
       "        [0.3019, 0.2977, 0.2139,  ..., 0.2237, 0.8934, 0.2871],\n",
       "        [0.2670, 0.2981, 0.2622,  ..., 0.2303, 0.2871, 0.9314]],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<MatmulBackward>)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4833d4eb-765f-432d-bf64-2cf513066d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NaNs encountered when trying to perform matrix-vector multiplication",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/24771440/ipykernel_162426/3570403056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvQuadLogDet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         inv_quad_term, logdet_term = func(\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_quad_log_det.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_logdet_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0msolves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         return utils.linear_cg(\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py\u001b[0m in \u001b[0;36mlinear_cg\u001b[0;34m(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Check for NaNs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaNs encountered when trying to perform matrix-vector multiplication\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# Sometime we're lucky and the preconditioner solves the system right away\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NaNs encountered when trying to perform matrix-vector multiplication"
     ]
    }
   ],
   "source": [
    "loss = -mll(output, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03928318-cca0-4ca9-9f9b-d510ea8f8f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9546, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "47d4e30a-cd9c-478b-aa6b-b8756f061ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_x,\n",
    "          train_y,\n",
    "          n_devices,\n",
    "          output_device,\n",
    "          checkpoint_size,\n",
    "          preconditioner_size,\n",
    "          n_training_iter,\n",
    "          lr\n",
    "):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "    with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "         gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            return loss\n",
    "\n",
    "        loss = closure()\n",
    "        loss.backward()\n",
    "\n",
    "        for i in range(n_training_iter):\n",
    "            options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "            loss, _, _, _, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "            print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                i + 1, n_training_iter, loss.item(),\n",
    "                model.covar_module.module.base_kernel.lengthscale.item(),\n",
    "                model.likelihood.noise.item()\n",
    "            ))\n",
    "\n",
    "            if fail:\n",
    "                print('Convergence reached!')\n",
    "                break\n",
    "\n",
    "    print(f\"Finished training on {train_x.size(0)} data points using {n_devices} GPUs.\")\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39813038-7c65-4d34-a177-8f01d5feb080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2712df6a-ba76-4104-965e-008f91a5c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4 -- Kernel partition size: 0\n",
      "RuntimeError: Found dtype Float but expected Double\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py:102: NumericalWarning: NaNs encountered in preconditioner computation. Attempting to continue without preconditioning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4 -- Kernel partition size: 5000\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 2500\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 1250\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 625\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 313\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 157\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 79\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 40\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 20\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 10\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 5\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 3\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def find_best_gpu_setting(train_x,\n",
    "                          train_y,\n",
    "                          n_devices,\n",
    "                          output_device,\n",
    "                          preconditioner_size\n",
    "):\n",
    "    N = train_x.size(0)\n",
    "\n",
    "    # Find the optimum partition/checkpoint size by decreasing in powers of 2\n",
    "    # Start with no partitioning (size = 0)\n",
    "    settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]\n",
    "\n",
    "    for checkpoint_size in settings:\n",
    "        print('Number of devices: {} -- Kernel partition size: {}'.format(n_devices, checkpoint_size))\n",
    "        try:\n",
    "            # Try a full forward and backward pass with this setting to check memory usage\n",
    "            _, _ = train(model, train_x, train_y,\n",
    "                         n_devices=n_devices, output_device=output_device,\n",
    "                         checkpoint_size=checkpoint_size,\n",
    "                         preconditioner_size=preconditioner_size, n_training_iter=1, lr=0.05)\n",
    "\n",
    "            # when successful, break out of for-loop and jump to finally block\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            print('RuntimeError: {}'.format(e))\n",
    "        except AttributeError as e:\n",
    "            print('AttributeError: {}'.format(e))\n",
    "        finally:\n",
    "            # handle CUDA OOM error\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return checkpoint_size\n",
    "\n",
    "# Set a large enough preconditioner size to reduce the number of CG iterations run\n",
    "preconditioner_size = 100\n",
    "checkpoint_size = find_best_gpu_setting(train_x, train_y,\n",
    "                                        n_devices=n_devices,\n",
    "                                        output_device=output_device,\n",
    "                                        preconditioner_size=preconditioner_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2255b-7636-4bd3-9b8a-47bdef4f2948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
