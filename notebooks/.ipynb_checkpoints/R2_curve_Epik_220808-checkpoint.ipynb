{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3c8288-f9c7-4a82-85cd-9af831755acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f3a2f3-9f4d-4c6a-a60e-194c428abb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import os\n",
    "import GPUtil\n",
    "import importlib\n",
    "\n",
    "def sgpu():\n",
    "    GPUtil.showUtilization()\n",
    "\n",
    "def rl(module):\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f62c83d-afbd-437e-8092-fbf352e388c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "sgpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6e52c0-7f3e-444b-9a93-73866acba381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26c5c81-59bd-4b6c-8f05-35718960fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EpiK.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4ff720-37a3-4cfd-a171-b727c829e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs = 8; output device = 0\n"
     ]
    }
   ],
   "source": [
    "output_device = 0\n",
    "n_devices = torch.cuda.device_count()\n",
    "models.set_params(output_device, n_devices)\n",
    "print(\"number of GPUs = {}; output device = {}\".\n",
    "      format(n_devices, torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e266f6d1-6a6f-45b4-bad3-e46ef9f065ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EpiK.functions import get_data, get_envs, set_data_path\n",
    "set_data_path(\"../matsui_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd9fbf2-6d86-4bd0-8969-92892866ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sizes\n",
    "props = [.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0335aa4d-a24c-442f-8fc7-dd775e15bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_point sizes\n",
    "partitions = [2, 2, 2, 2, 4, 4, 4, 4, 16, 32, 64, 80]\n",
    "pd.DataFrame({\"props\":props, \"partitions\":partitions}).to_csv(\"partition_sizes.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba7527b-8071-4486-a333-99346661d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_sizes = pd.read_csv(\"partition_sizes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b19d0-bc0d-4b11-bc08-a0f498eb8459",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026f761f-0a47-436d-9277-5cc343934c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_list = get_envs()\n",
    "env = env_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab6db51-a8bf-402c-8284-61ea0b9bc1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../EpiK/functions.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  geno_t = torch.tensor(geno_t, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "geno_t, pheno = get_data(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef14765-c39d-4591-837c-3c5cd47e53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_sub = np.where(np.array(pheno.pheno < -0.6) == False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565c048-4940-44f3-8248-bc5cd31466ef",
   "metadata": {},
   "source": [
    "### Loops to get R2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6224528-799c-4650-addb-4919921c304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EpiK.functions\n",
    "rl(EpiK.functions)\n",
    "from EpiK.functions import train_model_cv\n",
    "\n",
    "EpiK.functions.output_device = output_device\n",
    "EpiK.functions.n_devices = n_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65567220-5243-4fa1-ae58-242d4746195d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>props</th>\n",
       "      <th>train_size</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.356593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>9502</td>\n",
       "      <td>0.513126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>19005</td>\n",
       "      <td>0.556292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>38010</td>\n",
       "      <td>0.601241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>57015</td>\n",
       "      <td>0.614587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.40</td>\n",
       "      <td>76020</td>\n",
       "      <td>0.619015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>95025</td>\n",
       "      <td>0.630507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.60</td>\n",
       "      <td>114030</td>\n",
       "      <td>0.643053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.70</td>\n",
       "      <td>133035</td>\n",
       "      <td>0.639567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.80</td>\n",
       "      <td>152040</td>\n",
       "      <td>0.648036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.90</td>\n",
       "      <td>171045</td>\n",
       "      <td>0.650141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.99</td>\n",
       "      <td>188150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    props  train_size        r2\n",
       "0    0.01        1900  0.356593\n",
       "1    0.05        9502  0.513126\n",
       "2    0.10       19005  0.556292\n",
       "3    0.20       38010  0.601241\n",
       "4    0.30       57015  0.614587\n",
       "5    0.40       76020  0.619015\n",
       "6    0.50       95025  0.630507\n",
       "7    0.60      114030  0.643053\n",
       "8    0.70      133035  0.639567\n",
       "9    0.80      152040  0.648036\n",
       "10   0.90      171045  0.650141\n",
       "11   0.99      188150  0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"r2s_epik.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab4c53e5-3571-41a7-8feb-78bc26506ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EpiK.kernels import DiKernel\n",
    "ker = DiKernel()\n",
    "ker.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "ker.raw_eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6264e78-683b-4bed-9da7-b0510f1f552d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on training data proportion = 0.01\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.05\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.1\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.2\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.3\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.4\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.5\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.6\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.7\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.8\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.9\n",
      "r2_score found, skipping to next\n",
      "working on training data proportion = 0.99\n",
      "no r2_score recorded, proceeding to calculate\n",
      "training GP model using CV\n",
      "working on iteration 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(props)):\n",
    "    \n",
    "    print(\"working on training data proportion = {}\".format(props[i]))\n",
    "    \n",
    "    if results.iloc[i].r2 != 0.:\n",
    "        print(\"r2_score found, skipping to next\")\n",
    "    \n",
    "    else:\n",
    "        print(\"no r2_score recorded, proceeding to calculate\")\n",
    "        np.random.seed(100)\n",
    "        train_size = np.round(props[i]*len(inds_sub)).astype('int')\n",
    "        sub = np.random.choice(inds_sub, train_size)\n",
    "        sub_t = np.random.choice(list(set(inds_sub).difference(sub)), 4000)\n",
    "        train_x = geno_t[sub]\n",
    "        train_y = torch.tensor(np.array(pheno.pheno[sub]), dtype=torch.float32)\n",
    "        test_x = geno_t[sub_t]\n",
    "        test_y = torch.tensor(np.array(pheno.pheno[sub_t]), dtype=torch.float32)\n",
    "        train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "        test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "        train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "        test_x, test_y = test_x.to(output_device), test_y.to(output_device)\n",
    "\n",
    "        # train model\n",
    "        print(\"training GP model using CV\")\n",
    "        ker, likelihood = train_model_cv(ker, train_x, train_y, 50, .1)\n",
    "        \n",
    "\n",
    "        # make predictions - build model\n",
    "        torch.cuda.empty_cache()\n",
    "        model = models.ExactGPModel(train_x, train_y, likelihood, ker).to(output_device)\n",
    "\n",
    "        # make predictions - loop to increase partition_size until passes\n",
    "        loop = True\n",
    "        while loop:\n",
    "            try: \n",
    "                partition_size = partition_sizes.iloc[i, 1]\n",
    "                print(\"try doing inference underpartition size = {}\".format(partition_size))\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()                \n",
    "\n",
    "                model.eval()\n",
    "                likelihood.eval()\n",
    "                with gpytorch.beta_features.checkpoint_kernel(train_x.shape[0]//int(partition_size)):\n",
    "                    f_preds = model(test_x)\n",
    "                    \n",
    "                f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "                y_test = test_y.detach().cpu().numpy()\n",
    "                r2_score = r2(y_test, f_mean)                \n",
    "                results.iloc[i, 2] = r2_score\n",
    "                loop = False            \n",
    "\n",
    "            except: \n",
    "                print(\"failed on current partition_size, increasing by 5\")\n",
    "                partition_sizes.iloc[i, 1] = partition_sizes.iloc[i,1] + 5\n",
    "                partition_sizes.to_csv(\"partition_sizes.csv\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad320ce1-ca6a-465b-8413-548a63846340",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"r2_epik.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
