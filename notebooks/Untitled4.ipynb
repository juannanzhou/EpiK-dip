{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bff7c28-b37e-424e-95d1-1035f03fd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ae9952-691f-4759-9a78-8b53d20e5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360d08db-7d78-44c8-84e6-db093a078f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae487b32-a916-4129-87b8-0d8e02eb09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9519491-2f40-4abd-904f-f98f9640b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5bcfbf4-b405-476e-ac21-df6136e1569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"96ghpptzvf-4/SData2/CoCl2_geno.txt\", sep='\\t', nrows=5, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31202a99-ab1b-421b-8a9d-cbe7d33b876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d9b4da-de21-45cf-8d16-dd4362aa0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.load('matsui_geno_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9811fd-b94c-441b-8775-b4e8b80d4145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geno_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33129b2f-7814-4432-901d-78b7adf9bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.transpose(geno_t, 0, 1)\n",
    "N, L = geno_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4001429-b8b3-46e7-967a-c1a5b0219194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(\"96ghpptzvf-4/SData6/CoCl2_pheno.txt\", sep='\\t', engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1eea171-8613-405f-afeb-2f617b20b70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pheno</th>\n",
       "      <th>MATa</th>\n",
       "      <th>MATalpha</th>\n",
       "      <th>geno</th>\n",
       "      <th>qnorm</th>\n",
       "      <th>MATa_mid</th>\n",
       "      <th>MATalpha_mid</th>\n",
       "      <th>midparent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021705</td>\n",
       "      <td>y39_A012</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A012</td>\n",
       "      <td>-0.021147</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.131384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.184045</td>\n",
       "      <td>y39_A02</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A02</td>\n",
       "      <td>-0.924553</td>\n",
       "      <td>-0.286352</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.311561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.133887</td>\n",
       "      <td>y39_A03</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A03</td>\n",
       "      <td>-0.640047</td>\n",
       "      <td>-0.896266</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>-0.616517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021991</td>\n",
       "      <td>y39_A04</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A04</td>\n",
       "      <td>-0.022688</td>\n",
       "      <td>0.593958</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>0.128595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088438</td>\n",
       "      <td>y39_A05</td>\n",
       "      <td>BYa_1C_A10</td>\n",
       "      <td>BYa_1C_A10.y39_A05</td>\n",
       "      <td>0.574957</td>\n",
       "      <td>0.576434</td>\n",
       "      <td>-0.336769</td>\n",
       "      <td>0.119833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pheno      MATa    MATalpha                 geno     qnorm  MATa_mid  \\\n",
       "0 -0.021705  y39_A012  BYa_1C_A10  BYa_1C_A10.y39_A012 -0.021147  0.074002   \n",
       "1 -0.184045   y39_A02  BYa_1C_A10   BYa_1C_A10.y39_A02 -0.924553 -0.286352   \n",
       "2 -0.133887   y39_A03  BYa_1C_A10   BYa_1C_A10.y39_A03 -0.640047 -0.896266   \n",
       "3 -0.021991   y39_A04  BYa_1C_A10   BYa_1C_A10.y39_A04 -0.022688  0.593958   \n",
       "4  0.088438   y39_A05  BYa_1C_A10   BYa_1C_A10.y39_A05  0.574957  0.576434   \n",
       "\n",
       "   MATalpha_mid  midparent  \n",
       "0     -0.336769  -0.131384  \n",
       "1     -0.336769  -0.311561  \n",
       "2     -0.336769  -0.616517  \n",
       "3     -0.336769   0.128595  \n",
       "4     -0.336769   0.119833  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935e7bbc-7f10-4b47-866b-8ef420348720",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.set_index('geno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96895ce0-fff1-4b90-8c38-7732f4e20df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.loc[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b72cd-c626-4d8d-9037-c661d48fa554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ea0c7-d313-4733-a2ea-51ac780df663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaed242-4daf-4e58-b33a-ad98d0aa8a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b9364a5-0570-4596-9248-d59683e9f2a3",
   "metadata": {},
   "source": [
    "### Test Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5870ec2b-d895-4641-ac29-1a865cba467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.random.choice(range(N), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "caa98000-8d2f-43a2-9ee7-9c2388e44764",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_t = np.random.choice(list(set(range(N)).difference(sub)), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bb991116-b69a-482c-ad83-2714b4daf6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]))\n",
    "\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "438068fc-6331-4d78-a3af-74be9d40a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "output_device = torch.device('cuda:0')\n",
    "\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19b3b9c7-1199-4448-85d0-547846392012",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ad59b9e-48bb-4003-a44c-7e53ef9282e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 4 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44181f62-241d-4c9d-aea3-b95993fdd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(geno1, geno2):\n",
    "  \"\"\"build distance tensor between two sets of genotypes\n",
    "  geno1, geno2: n x L, m x L torch tensors\n",
    "  \n",
    "  \"\"\"\n",
    "  geno1_h0 = 1.*(geno1 == 0.)\n",
    "  geno1_h1 = 1.*(geno1 == 2.)\n",
    "  geno2_h0 = 1.*(geno2 == 0.)\n",
    "  geno2_h1 = 1.*(geno2 == 2.)\n",
    "  S1 = torch.matmul(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "  S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "  D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "  D1 = L - S1 - S2 - D2\n",
    "\n",
    "  return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "34e30182-71db-4914-a232-6f163873c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(log_lda, log_eta, dvec):\n",
    "    \"\"\"\n",
    "    log_lda, log_eta -- torch tensors\n",
    "    dvec -- 4 x n x m torch tensor\n",
    "    \"\"\"\n",
    "    lda = torch.exp(log_lda)\n",
    "    eta = torch.exp(log_eta)\n",
    "    return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "          *((1 - lda + eta)**dvec[3])\n",
    "          *((1 + eta)**(dvec[0] - L/2)) \n",
    "          * (1-eta)**dvec[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "5f88ae02-6587-4718-9a84-33af63e3e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "class DiKernel(gpytorch.kernels.Kernel):\n",
    "  \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "  is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "  def __init__(self, \n",
    "                lda_prior=None, lda_constraint=None, \n",
    "                eta_prior=None, eta_constraint=None,\n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # register the raw parameter\n",
    "      self.register_parameter(\n",
    "          name='raw_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      self.register_parameter(\n",
    "          name='raw_eta', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      # set the parameter constraint to be positive, when nothing is specified\n",
    "      if lda_constraint is None:\n",
    "          lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      if eta_constraint is None:\n",
    "          eta_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      # register the constraint\n",
    "      self.register_constraint(\"raw_lda\", lda_constraint)\n",
    "      self.register_constraint(\"raw_eta\", eta_constraint)\n",
    "\n",
    "      \n",
    "  # now set up the 'actual' paramter\n",
    "  @property\n",
    "  def lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_lda_constraint.transform(self.raw_lda)\n",
    "\n",
    "  @property\n",
    "  def eta(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_eta_constraint.transform(self.raw_eta)\n",
    "\n",
    "  @lda.setter\n",
    "  def lda(self, value):\n",
    "      return self._set_lda(value)\n",
    "\n",
    "  @eta.setter\n",
    "  def eta(self, value):\n",
    "      return self._set_eta(value)\n",
    "\n",
    "  def forward(self, x1, x2, **params):\n",
    "    diff = d(x1, x2)\n",
    "    return k(lda, eta, diff)\n",
    "#     return k(self.lda, self.eta, diff)\n",
    "#     return self.eta*diff[0]\n",
    "#     dvec = diff\n",
    "#     log_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "#     log_eta = torch.nn.Parameter(torch.tensor(-12.))\n",
    "#     lda = torch.exp(log_lda)\n",
    "#     eta = torch.exp(log_eta)\n",
    "    \n",
    "#     return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "#     *((1 - lda + eta)**dvec[3])\n",
    "#     *((1 + eta)**(dvec[0] - L/2)) \n",
    "#     * (1-eta)**dvec[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "63bb2e51-1a27-41b7-bb5c-dd0b8f325381",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "0cd0a785-cec9-4767-872d-424d9fce9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            DiKernel(), device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "d434c224-f533-4554-a8ea-d8a31190316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "#   def __init__(self, train_x, train_y, likelihood):\n",
    "#     super().__init__(train_x, train_y, likelihood)\n",
    "#     self.mean_module = gpytorch.means.ConstantMean()\n",
    "#     self.covar_module = DiKernel()\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     mean_x = self.mean_module(x)\n",
    "#     covar_x = self.covar_module(x)\n",
    "#     return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "1af0f525-d353-4580-bac7-408c5f4fa75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = DiGPModel(train_x, train_y, likelihood)\n",
    "model = model.double().to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "75c9cdd3-8648-4823-ad80-1e0aec03e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.covar_module.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "model.covar_module.raw_eta = torch.nn.Parameter(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e5ef61c0-f720-44a6-a33e-bce3f12d9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "1d735461-12a0-4d11-8b9a-15e7c0f3c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': lda},\n",
    "    {'params': eta}\n",
    "], lr = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "5b283e7d-be3d-42a9-b9f6-5a14600bbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "34e47ab2-9155-424e-9bdf-5a58317493b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -mll(output, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "ec0e2171-081a-43c6-b80f-61b62e2e4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72e62f-eb13-49d1-9ac7-7962fdd9997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "47d4e30a-cd9c-478b-aa6b-b8756f061ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_x,\n",
    "          train_y,\n",
    "          n_devices,\n",
    "          output_device,\n",
    "          checkpoint_size,\n",
    "          preconditioner_size,\n",
    "          n_training_iter,\n",
    "          lr\n",
    "):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "    with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "         gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            return loss\n",
    "\n",
    "        loss = closure()\n",
    "        loss.backward()\n",
    "\n",
    "        for i in range(n_training_iter):\n",
    "            options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "            loss, _, _, _, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "            print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "                i + 1, n_training_iter, loss.item(),\n",
    "                model.covar_module.module.base_kernel.lengthscale.item(),\n",
    "                model.likelihood.noise.item()\n",
    "            ))\n",
    "\n",
    "            if fail:\n",
    "                print('Convergence reached!')\n",
    "                break\n",
    "\n",
    "    print(f\"Finished training on {train_x.size(0)} data points using {n_devices} GPUs.\")\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39813038-7c65-4d34-a177-8f01d5feb080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2712df6a-ba76-4104-965e-008f91a5c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4 -- Kernel partition size: 0\n",
      "RuntimeError: Found dtype Float but expected Double\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py:102: NumericalWarning: NaNs encountered in preconditioner computation. Attempting to continue without preconditioning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4 -- Kernel partition size: 5000\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 2500\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 1250\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 625\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 313\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 157\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 79\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 40\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 20\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 10\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 5\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n",
      "Number of devices: 4 -- Kernel partition size: 3\n",
      "RuntimeError: The kernel MultiDeviceKernel is not equipped to handle and diag. Expected size torch.Size([10000]). Got size torch.Size([10000, 10000])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def find_best_gpu_setting(train_x,\n",
    "                          train_y,\n",
    "                          n_devices,\n",
    "                          output_device,\n",
    "                          preconditioner_size\n",
    "):\n",
    "    N = train_x.size(0)\n",
    "\n",
    "    # Find the optimum partition/checkpoint size by decreasing in powers of 2\n",
    "    # Start with no partitioning (size = 0)\n",
    "    settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]\n",
    "\n",
    "    for checkpoint_size in settings:\n",
    "        print('Number of devices: {} -- Kernel partition size: {}'.format(n_devices, checkpoint_size))\n",
    "        try:\n",
    "            # Try a full forward and backward pass with this setting to check memory usage\n",
    "            _, _ = train(model, train_x, train_y,\n",
    "                         n_devices=n_devices, output_device=output_device,\n",
    "                         checkpoint_size=checkpoint_size,\n",
    "                         preconditioner_size=preconditioner_size, n_training_iter=1, lr=0.05)\n",
    "\n",
    "            # when successful, break out of for-loop and jump to finally block\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            print('RuntimeError: {}'.format(e))\n",
    "        except AttributeError as e:\n",
    "            print('AttributeError: {}'.format(e))\n",
    "        finally:\n",
    "            # handle CUDA OOM error\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return checkpoint_size\n",
    "\n",
    "# Set a large enough preconditioner size to reduce the number of CG iterations run\n",
    "preconditioner_size = 100\n",
    "checkpoint_size = find_best_gpu_setting(train_x, train_y,\n",
    "                                        n_devices=n_devices,\n",
    "                                        output_device=output_device,\n",
    "                                        preconditioner_size=preconditioner_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2255b-7636-4bd3-9b8a-47bdef4f2948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
