{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee8fa84-c71b-493a-9c8d-4fa4b0829463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4ba6c4-554a-499a-9a57-831ce9fef021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def rl():\n",
    "    importlib.reload(Di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db4d4b5-112f-4432-b9e2-dfa948d538bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ec58e7-4447-4f3e-bf5f-ed51affca87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6e272d-9d05-4cfe-912d-a328c097ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f309085-b33f-4f85-bef7-26b8f811d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_file_list = []\n",
    "for path, currentDirectory, files in os.walk(\"96ghpptzvf-4/SData2/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"geno.txt\"):\n",
    "            geno_file_list.append(file)\n",
    "\n",
    "geno_file_list = list(set(geno_file_list))\n",
    "\n",
    "env_list = [file.split('_')[0] for file in geno_file_list]\n",
    "\n",
    "env_list = sorted(env_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a217d511-3dfc-4ec0-b62a-bf7f2e81c1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaCl\n"
     ]
    }
   ],
   "source": [
    "env = env_list[5]\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232f0e16-2fab-476c-a9ce-af777f066603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"96ghpptzvf-4/SData2/\"+ env + \"_geno.txt\", sep='\\t', nrows=5, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9b3d44-db85-47bd-850b-d4b4160be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea5557b-a26d-453d-aae4-e45be587f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NaCl_matsui_geno_t.pt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env + '_matsui_geno_t.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d9ea16-ec8c-4142-a02a-2c46fe7ae643",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.load(env + '_matsui_geno_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe9f973-6d51-4e9c-a7d2-4575ce8cc93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 2., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.],\n",
       "        [1., 2., 2.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geno_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfde8729-0f01-4ac5-a558-9ab90be05613",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_t = torch.transpose(geno_t, 0, 1)\n",
    "N, L = geno_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a5953bc-1441-4b15-9047-bc92c8153557",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(\"96ghpptzvf-4/SData6/\" + env + \"_pheno.txt\", sep='\\t', engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd03651-f9ce-47a9-bb6a-a8375ea5d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.set_index('geno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e4fc78-4a7f-457e-a57f-57a3d677f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pheno.loc[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f19cac8-653a-4206-a887-14376ee31dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pheno.pheno)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82f55c-a8ec-42c1-8108-a6de0753b118",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1059cb8-6b75-4dd4-af5b-c791f1537f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 8 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b1a501f-5cb9-4e04-b72c-ff26fc9f5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfff37-e18c-4095-933f-92e27ee7e05f",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22d16029-a360-4b5f-aa0d-01fd19adfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_sub = np.where(np.array(pheno.pheno < -0.6) == False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a0be55d-c922-40f3-babe-ec6c2892dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44bfd463-8723-4d71-b6b2-4b33ad425a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.random.choice(inds_sub, 10000)\n",
    "\n",
    "sub_t = np.random.choice(list(set(inds_sub).difference(sub)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f5d3767-89f5-4e30-a005-8ca73d024960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]), dtype=torch.float32)\n",
    "\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ff3840c-1f74-47f9-932b-70dfc5c5d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32a492-76eb-4689-85ff-163fcdda4122",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a24b0166-d4b7-4ee4-942d-01cd6430db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(geno1, geno2):\n",
    "  \"\"\"build distance tensor between two sets of genotypes\n",
    "  geno1, geno2: n x L, m x L torch tensors\n",
    "  \n",
    "  \"\"\"\n",
    "  geno1_h0 = 1.*(geno1 == 0.)\n",
    "  geno1_h1 = 1.*(geno1 == 2.)\n",
    "  geno2_h0 = 1.*(geno2 == 0.)\n",
    "  geno2_h1 = 1.*(geno2 == 2.)\n",
    "  S1 = torch.matmul(geno1%2., torch.transpose(geno2%2., 0, 1))\n",
    "  S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "  D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "  D1 = L - S1 - S2 - D2\n",
    "\n",
    "  return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f7995e8-94d8-4f9b-b3fc-373ff8afee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(log_lda, log_eta, dvec):\n",
    "    \"\"\"\n",
    "    log_lda, log_eta -- torch tensors\n",
    "    dvec -- 4 x n x m torch tensor\n",
    "    \"\"\"\n",
    "    lda = torch.exp(log_lda)\n",
    "    eta = torch.exp(log_eta)\n",
    "    return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "          *((1 - lda + eta)**dvec[3])\n",
    "          *((1 + eta)**(dvec[0] - L/2)) \n",
    "          * (1-eta)**dvec[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dcf297b-3e13-4654-970f-8f63e85c53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "\n",
    "class DiKernel(gpytorch.kernels.Kernel):\n",
    "  \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "  is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "  def __init__(self, \n",
    "                lda_prior=None, lda_constraint=None, \n",
    "                eta_prior=None, eta_constraint=None,\n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "      # register the raw parameter\n",
    "      self.register_parameter(\n",
    "          name='raw_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      self.register_parameter(\n",
    "          name='raw_eta', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "      )\n",
    "\n",
    "      # set the parameter constraint to be positive, when nothing is specified\n",
    "      if lda_constraint is None:\n",
    "          lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      if eta_constraint is None:\n",
    "          eta_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "      # register the constraint\n",
    "      self.register_constraint(\"raw_lda\", lda_constraint)\n",
    "      self.register_constraint(\"raw_eta\", eta_constraint)\n",
    "\n",
    "      \n",
    "  # now set up the 'actual' paramter\n",
    "  @property\n",
    "  def lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_lda_constraint.transform(self.raw_lda)\n",
    "\n",
    "  @property\n",
    "  def eta(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_eta_constraint.transform(self.raw_eta)\n",
    "\n",
    "  @lda.setter\n",
    "  def lda(self, value):\n",
    "      return self._set_lda(value)\n",
    "\n",
    "  @eta.setter\n",
    "  def eta(self, value):\n",
    "      return self._set_eta(value)\n",
    "\n",
    "  def forward(self, x1, x2, diag=False, **params):\n",
    "      diff = d(x1, x2)\n",
    "      K = k(self.lda, self.eta, diff)\n",
    "      if diag:\n",
    "        K = K[0]\n",
    "      return K\n",
    "      \n",
    "\n",
    "    \n",
    "class DiGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            DiKernel(), device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c2947e6-970a-40b5-92ec-2a5813567fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiGPModel2(gpytorch.models.ExactGP):\n",
    "\n",
    "  def __init__(self, train_x, train_y, likelihood):\n",
    "    super().__init__(train_x, train_y, likelihood)\n",
    "    self.mean_module = gpytorch.means.ConstantMean()\n",
    "    base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean_x = self.mean_module(x)\n",
    "    covar_x = self.covar_module(x)\n",
    "    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63f03dd8-25a4-4ca0-b23c-1e0ea51d25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, likelihood, train_x, train_y, training_iter=300, lr=.05):\n",
    "    losses = []\n",
    "    \n",
    "    \"\"\"fitting hyperparameters of model by maximizing marginal log likelihood\"\"\"\n",
    "    # Use the adam optimizer, this includes GaussianLikelihood parameters\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "      if i%20==0:\n",
    "        print(i)\n",
    "      else: pass\n",
    "      # Zero gradients from previous iteration\n",
    "      optimizer.zero_grad()\n",
    "      # Output from model\n",
    "      output = model(train_x)\n",
    "      # Calc loss and backprop gradients\n",
    "      loss = -mll(output, train_y)\n",
    "      loss.backward()\n",
    "      losses.append(loss.item())    \n",
    "      optimizer.step()\n",
    "      del loss\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be7bad5d-2e17-4905-8a54-dc3d7df215a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_x,\n",
    "          train_y,\n",
    "          checkpoint_size,\n",
    "          preconditioner_size,\n",
    "          n_training_iter,\n",
    "):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.05)\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "    with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "         gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            return loss\n",
    "\n",
    "        loss = closure()\n",
    "        loss.backward()\n",
    "\n",
    "        for i in range(n_training_iter):\n",
    "            options = {'closure': closure, 'current_loss': loss, 'max_ls': 10}\n",
    "            loss, _, _, _, _, _, _, fail = optimizer.step(options)\n",
    "\n",
    "\n",
    "            if fail:\n",
    "                print('Convergence reached!')\n",
    "                break\n",
    "\n",
    "    print(f\"Finished training on {train_x.size(0)} data points using {n_devices} GPUs.\")\n",
    "    return model, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c856eda-9410-4cd9-bd4a-09217232fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ker = DiKernel().to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bc948bd-b93f-40e1-be76-8c7fa9ff342c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7742])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05945-e264-4ef8-986e-16ae38cc5189",
   "metadata": {},
   "source": [
    "### Test kernel partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd74c61a-e3e9-4bb2-9d85-123e949c0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "model = DiGPModel(train_x, train_y, likelihood)\n",
    "model.covar_module.module.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "model.covar_module.module.raw_eta = torch.nn.Parameter(torch.tensor(-12.))\n",
    "model = model.to(output_device).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab989b92-8f0e-422c-97b8-193a58bada62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:234: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.sum(mul_storage, -2, keepdim=True, out=alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9461446967366339,\n",
       " 0.9393497962210806,\n",
       " 0.9287743682830291,\n",
       " 0.9202285981613599,\n",
       " 0.9123845196837506,\n",
       " 0.9027624041609574,\n",
       " 0.8967799546559347,\n",
       " 0.886187797508634,\n",
       " 0.8782239363244382,\n",
       " 0.8692532599983804,\n",
       " 0.8608765731476844,\n",
       " 0.8511201774932358,\n",
       " 0.8417995938618251,\n",
       " 0.8337225430858131,\n",
       " 0.8257593285879055,\n",
       " 0.8160867192560063,\n",
       " 0.8065600291177712,\n",
       " 0.7996521533107448,\n",
       " 0.7888673516599193,\n",
       " 0.7782118149400312,\n",
       " 0.7712308687170754,\n",
       " 0.761546954409842,\n",
       " 0.7540557936424458,\n",
       " 0.745267631468417,\n",
       " 0.7353718579223525,\n",
       " 0.7257879660478851,\n",
       " 0.7174284610028813,\n",
       " 0.7094897933476617,\n",
       " 0.7001184936875835,\n",
       " 0.6891478900331184,\n",
       " 0.6797553291740935,\n",
       " 0.6708631928185658,\n",
       " 0.6607190104750966,\n",
       " 0.6531638167066215,\n",
       " 0.6434934301424597,\n",
       " 0.6338166171987343,\n",
       " 0.6214873220548148,\n",
       " 0.6144166697928038,\n",
       " 0.6046250483620859,\n",
       " 0.5967953321239551,\n",
       " 0.5885943359228094,\n",
       " 0.5765335670606635,\n",
       " 0.5667225391787233,\n",
       " 0.5582655666494835,\n",
       " 0.5472791672459493,\n",
       " 0.5369799266400738,\n",
       " 0.5293418992732828,\n",
       " 0.517583784824373,\n",
       " 0.5102277014218825,\n",
       " 0.500308775171639,\n",
       " 0.48899008658172716,\n",
       " 0.4790238537496351,\n",
       " 0.4682603138061187,\n",
       " 0.45797622914891245,\n",
       " 0.449670687528734,\n",
       " 0.4395854523834202,\n",
       " 0.43243690274920304,\n",
       " 0.41988189974290147,\n",
       " 0.40869794822368516,\n",
       " 0.4010221561334993,\n",
       " 0.39002891323717115,\n",
       " 0.3802706179321912,\n",
       " 0.37242514615878336,\n",
       " 0.36155617349052865,\n",
       " 0.3508492241992351,\n",
       " 0.3391508121846868,\n",
       " 0.3314604060729028,\n",
       " 0.31982100485799514,\n",
       " 0.31145608015245835,\n",
       " 0.30156453375949904,\n",
       " 0.2899244839677192,\n",
       " 0.2779469422654908,\n",
       " 0.2709834980460968,\n",
       " 0.2583721103169096,\n",
       " 0.24785615766052443,\n",
       " 0.2380832394950496,\n",
       " 0.22754349827210346,\n",
       " 0.21973165852386164,\n",
       " 0.20675336491796417,\n",
       " 0.19904835229246273,\n",
       " 0.18867388392951626,\n",
       " 0.1788269945814718,\n",
       " 0.16717185082700545,\n",
       " 0.15680696560539129,\n",
       " 0.14724278525793116,\n",
       " 0.1371581746153006,\n",
       " 0.1290141343191165,\n",
       " 0.11956696493595183,\n",
       " 0.10612195257558951,\n",
       " 0.09412807443427865,\n",
       " 0.08494383987310866,\n",
       " 0.07562104884004493,\n",
       " 0.06626399341518445,\n",
       " 0.05562881090089213,\n",
       " 0.043792463929537555,\n",
       " 0.035099294291047044,\n",
       " 0.02545436126643181,\n",
       " 0.017348771662287984,\n",
       " 0.004128825559275174,\n",
       " -0.007544479187887555,\n",
       " -0.016429929108912437,\n",
       " -0.027370225960530663,\n",
       " -0.03616091341704068,\n",
       " -0.0459154988396318,\n",
       " -0.06020120243563397,\n",
       " -0.06678914265406802,\n",
       " -0.07890473990954724,\n",
       " -0.0866562714327738,\n",
       " -0.09873220344277615,\n",
       " -0.1069392965093428,\n",
       " -0.11874041468590713,\n",
       " -0.1262581084215808,\n",
       " -0.13940707510556294,\n",
       " -0.1478089972410473,\n",
       " -0.16212585560813314,\n",
       " -0.17084450787929892,\n",
       " -0.17782131049419678,\n",
       " -0.1899046946351635,\n",
       " -0.1992930807053481,\n",
       " -0.21107846526499763,\n",
       " -0.22014004824006972,\n",
       " -0.23139108664150118,\n",
       " -0.23702609939134037,\n",
       " -0.24803131957272617,\n",
       " -0.26038384155677086,\n",
       " -0.2710797881119748,\n",
       " -0.28021913787940705,\n",
       " -0.289333247456175,\n",
       " -0.2988232968695191,\n",
       " -0.3107566665550896,\n",
       " -0.321250897706286,\n",
       " -0.32813736378585856,\n",
       " -0.34100300153195967,\n",
       " -0.34913616360124944,\n",
       " -0.3611278785898574,\n",
       " -0.3713788682385037,\n",
       " -0.3755550627288172,\n",
       " -0.38745211604778107,\n",
       " -0.4013471636201141,\n",
       " -0.41033908128601765,\n",
       " -0.41724467735584425,\n",
       " -0.425886623352646,\n",
       " -0.4357090695742731,\n",
       " -0.44629952115691907,\n",
       " -0.45945041291535055,\n",
       " -0.4652074236398896,\n",
       " -0.4755430325450138,\n",
       " -0.48382423557789284,\n",
       " -0.49292944529339916,\n",
       " -0.5035770728740241,\n",
       " -0.512764252201736,\n",
       " -0.5224278049685745,\n",
       " -0.5308547310473343,\n",
       " -0.540540895154906,\n",
       " -0.5505206753063636,\n",
       " -0.5589912389187428,\n",
       " -0.5702336930382872,\n",
       " -0.575468138266924,\n",
       " -0.5882649209920902,\n",
       " -0.5974905260924481,\n",
       " -0.6084937053358266,\n",
       " -0.6150700823971669,\n",
       " -0.6268433650912979,\n",
       " -0.6334124317524767,\n",
       " -0.6432361293388873,\n",
       " -0.6516048238953583,\n",
       " -0.6610962147305282,\n",
       " -0.6689584311961537,\n",
       " -0.6784220270201723,\n",
       " -0.6863632708513604,\n",
       " -0.6944075197769164,\n",
       " -0.7034959572681712,\n",
       " -0.7131985437067248,\n",
       " -0.7223768675568781,\n",
       " -0.7280247409688769,\n",
       " -0.7383345010306969,\n",
       " -0.7483591399070085,\n",
       " -0.7543243606682524,\n",
       " -0.7657507130302506,\n",
       " -0.7738217543726705,\n",
       " -0.7783729061006563,\n",
       " -0.7884617009242512,\n",
       " -0.7947442774722173,\n",
       " -0.8056652164846959,\n",
       " -0.8135410173040002,\n",
       " -0.8223270068462926,\n",
       " -0.8298867588651955,\n",
       " -0.8361404326754032,\n",
       " -0.8454153079718383,\n",
       " -0.8512163670256758,\n",
       " -0.8607218563065994,\n",
       " -0.867812258494726,\n",
       " -0.8735249046753246,\n",
       " -0.8849808489031251,\n",
       " -0.8862285029532055,\n",
       " -0.8966115307111994,\n",
       " -0.9071177839442711,\n",
       " -0.9141807838749565,\n",
       " -0.9202064903056458,\n",
       " -0.926957418810432,\n",
       " -0.9391983316468823,\n",
       " -0.9439716509628341,\n",
       " -0.9469547472058263,\n",
       " -0.954868724108767,\n",
       " -0.9637115280848221,\n",
       " -0.974557530772194,\n",
       " -0.978371491124981,\n",
       " -0.9840888336888411,\n",
       " -0.9932763217103171,\n",
       " -0.9991423655694193,\n",
       " -1.0049506342185937,\n",
       " -1.011402022897776,\n",
       " -1.0198084252591921,\n",
       " -1.024493475854579,\n",
       " -1.0331389641278048,\n",
       " -1.041104548958227,\n",
       " -1.044008917683367,\n",
       " -1.0501258605327641,\n",
       " -1.0557301909306038,\n",
       " -1.0626128433925854,\n",
       " -1.0696267173097427,\n",
       " -1.0759208266185456,\n",
       " -1.080982947190157,\n",
       " -1.0863830789970312,\n",
       " -1.09485761165407,\n",
       " -1.0927993169323806,\n",
       " -1.1049106777110238,\n",
       " -1.1095105563347138,\n",
       " -1.1170462147145228,\n",
       " -1.11917594958493,\n",
       " -1.1249894811882495,\n",
       " -1.130692617382758,\n",
       " -1.1353039146247148,\n",
       " -1.1420702726383924,\n",
       " -1.148490264742018,\n",
       " -1.1514318075598624,\n",
       " -1.1590824656445642,\n",
       " -1.1619909541372972,\n",
       " -1.1698606762451373,\n",
       " -1.172249897976033,\n",
       " -1.1787278483755212,\n",
       " -1.1796955637984348,\n",
       " -1.1875818511978666,\n",
       " -1.1927942603376889,\n",
       " -1.1944309887852185,\n",
       " -1.1984384357580833,\n",
       " -1.2088259992225543,\n",
       " -1.2075610274577855,\n",
       " -1.2128098188547118,\n",
       " -1.2153175696101173,\n",
       " -1.2248178964018914,\n",
       " -1.226462923338409,\n",
       " -1.2312351817183522,\n",
       " -1.2319169936633052,\n",
       " -1.237617226243294,\n",
       " -1.2443883189355827,\n",
       " -1.2436306285591252,\n",
       " -1.2502539426147772,\n",
       " -1.2541222940379142,\n",
       " -1.2546421446276086,\n",
       " -1.261186746243583,\n",
       " -1.2627529718870794,\n",
       " -1.268017784013112,\n",
       " -1.2718511215776298,\n",
       " -1.2775535307355945,\n",
       " -1.2771824428668295,\n",
       " -1.285061226664681,\n",
       " -1.2844545079612222,\n",
       " -1.2925487906373136,\n",
       " -1.2921788127481242,\n",
       " -1.295861779770275,\n",
       " -1.2997109390298056,\n",
       " -1.3009497114740984,\n",
       " -1.3034236384596485,\n",
       " -1.30769262131838,\n",
       " -1.312537706694185,\n",
       " -1.314653260417458,\n",
       " -1.3195985799257435,\n",
       " -1.320305505002212,\n",
       " -1.3242291000131732,\n",
       " -1.3244975011383204,\n",
       " -1.3249723944663898,\n",
       " -1.3313674007015666,\n",
       " -1.3351978972721814,\n",
       " -1.3333823235328934,\n",
       " -1.3404853787774582,\n",
       " -1.3397912352540164,\n",
       " -1.342228930408012,\n",
       " -1.3462873258572712,\n",
       " -1.3477258339010774,\n",
       " -1.3535589195417053,\n",
       " -1.351743046838883,\n",
       " -1.353179077159949,\n",
       " -1.3620068132163938,\n",
       " -1.358122611998111,\n",
       " -1.3644599094995464,\n",
       " -1.366662051505082,\n",
       " -1.368824067877883,\n",
       " -1.3740763244239906,\n",
       " -1.3745112162935906,\n",
       " -1.3791509836064861,\n",
       " -1.3745571789349846,\n",
       " -1.3776569220766401,\n",
       " -1.3797160387127256,\n",
       " -1.386699687160423,\n",
       " -1.3863597115541297,\n",
       " -1.3862975158831623,\n",
       " -1.3938245561246096,\n",
       " -1.3957368199059632,\n",
       " -1.3921911223949965,\n",
       " -1.4009385922522144,\n",
       " -1.3983992189894021,\n",
       " -1.3996725737625593,\n",
       " -1.4035810429084543,\n",
       " -1.4094762336443105,\n",
       " -1.410117138271797,\n",
       " -1.4097566092905034,\n",
       " -1.412867301443372,\n",
       " -1.417717798811708,\n",
       " -1.4187524908273546,\n",
       " -1.4177899199635262,\n",
       " -1.4189928141246746,\n",
       " -1.4207407666405822,\n",
       " -1.4275819836785955,\n",
       " -1.4219802576443488,\n",
       " -1.4301551574285984,\n",
       " -1.432203705136451,\n",
       " -1.431502117014369,\n",
       " -1.4393205360243528,\n",
       " -1.4423358756117817,\n",
       " -1.4369808809109867,\n",
       " -1.444391114206059,\n",
       " -1.4425157280433867,\n",
       " -1.445222306094738,\n",
       " -1.4440342568977942,\n",
       " -1.4456206741706144,\n",
       " -1.4545639142025166,\n",
       " -1.4500642382699414,\n",
       " -1.44566667140353,\n",
       " -1.4545283151894723,\n",
       " -1.4545057126976595,\n",
       " -1.457958876746589,\n",
       " -1.4634304025787732,\n",
       " -1.4598491925107817,\n",
       " -1.4658054116215713,\n",
       " -1.4686673748692267,\n",
       " -1.4674704728335595,\n",
       " -1.4710223684784294,\n",
       " -1.4666897465288897,\n",
       " -1.4728310609634234,\n",
       " -1.4747326330210493,\n",
       " -1.4725692580059249,\n",
       " -1.4742219980667188,\n",
       " -1.4780137601417227,\n",
       " -1.4805359255341746,\n",
       " -1.4828012129762034,\n",
       " -1.483513268502803,\n",
       " -1.4819809795803747,\n",
       " -1.4781727229751584,\n",
       " -1.4894105840668304,\n",
       " -1.4884795600743366,\n",
       " -1.4854288577042396,\n",
       " -1.4931030670516963,\n",
       " -1.4885549481157903,\n",
       " -1.4953106235267521,\n",
       " -1.4996190141641148,\n",
       " -1.4951493277871026,\n",
       " -1.5043512308920994,\n",
       " -1.4941605520291854,\n",
       " -1.5070531591275709,\n",
       " -1.5005737598529052,\n",
       " -1.5035679099998713,\n",
       " -1.5069920674376356,\n",
       " -1.4996124824695547,\n",
       " -1.5069049845814235,\n",
       " -1.509499769269322,\n",
       " -1.510657736169405,\n",
       " -1.5122485993453911,\n",
       " -1.5186987620523238,\n",
       " -1.5161233111945962,\n",
       " -1.5168113026051018,\n",
       " -1.5212234288931579,\n",
       " -1.5225591573526362,\n",
       " -1.5192989315068879,\n",
       " -1.5247670184155293,\n",
       " -1.5215224941428982,\n",
       " -1.5240937232590683,\n",
       " -1.5211938678509551,\n",
       " -1.529127347850527,\n",
       " -1.529546033660323,\n",
       " -1.53224897409037,\n",
       " -1.5344247761532726,\n",
       " -1.5314161832796696,\n",
       " -1.5325833213927462,\n",
       " -1.5357006250714254,\n",
       " -1.53804512228937,\n",
       " -1.535133107810308,\n",
       " -1.5384837245891385,\n",
       " -1.536406842760321,\n",
       " -1.5376636027660646]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, likelihood, train_x, train_y, training_iter=400, lr=.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7ae46bb-1c07-4e98-b105-c2a53375682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_size=10\n",
    "preconditioner_size=100\n",
    "n_training_iter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "260e073b-ffc1-4144-b7dc-293dddfdab6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_66186/338918146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreconditioner_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_training_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_66186/2912562769.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_x, train_y, checkpoint_size, preconditioner_size, n_training_iter)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_66186/2912562769.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvQuadLogDet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         inv_quad_term, logdet_term = func(\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_quad_log_det.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_logdet_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0msolves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         return utils.linear_cg(\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py\u001b[0m in \u001b[0;36mlinear_cg\u001b[0;34m(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# residual: residual_{0} = b_vec - lhs x_{0}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmatmul_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_guess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madded_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msub_x1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_x1s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 sub_kernel_matrix = lazify(\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 )\n\u001b[1;32m    153\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_kernel_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x1_scattered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x2_subs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x1_scattered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x2_subs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train(model,train_x,train_y,checkpoint_size,preconditioner_size,n_training_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6acb469f-707d-4984-b65e-313de227cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), .02)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9477056c-6b6a-4a45-bfd2-4d84f4087a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "# Output from model\n",
    "output = model(train_x)\n",
    "# Calc loss and backprop gradients\n",
    "loss = -mll(output, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e561bbb1-56a2-43e9-8891-a06d5bf5c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "output = model(train_x)\n",
    "loss = -mll(output, train_y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aee64f62-421b-4a65-a5e6-df7deb738e85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:266: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  _jit_linear_cg_updates_no_precond(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_66186/2663539660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Make predictions on a small number of test points to get the test time caches computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvQuadLogDet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         inv_quad_term, logdet_term = func(\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_quad_log_det.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_logdet_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0msolves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         return utils.linear_cg(\n\u001b[0m\u001b[1;32m    659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py\u001b[0m in \u001b[0;36mlinear_cg\u001b[0;34m(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Get next alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m# alpha_{k} = (residual_{k-1}^T precon_residual{k-1}) / (p_vec_{k-1}^T mat p_vec_{k-1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mmvms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_conjugate_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprecond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_conjugate_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmul_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madded_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msub_x1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_x1s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 sub_kernel_matrix = lazify(\n\u001b[0;32m--> 151\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 )\n\u001b[1;32m    153\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_kernel_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_66186/934878869.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/36892328/ipykernel_66186/2641920585.py\u001b[0m in \u001b[0;36md\u001b[0;34m(geno1, geno2)\u001b[0m\n\u001b[1;32m     11\u001b[0m   S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n\u001b[1;32m     12\u001b[0m         + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n\u001b[0;32m---> 13\u001b[0;31m   D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n\u001b[0m\u001b[1;32m     14\u001b[0m         + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n\u001b[1;32m     15\u001b[0m   \u001b[0mD1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mS1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mS2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(1):\n",
    "\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a90b5681-2c45-404d-8973-bce43e87fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(500):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929013f0-505b-4c81-a79b-cbdf2a75b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_size = 10000\n",
    "preconditioner_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e9cd0-cb48-4647-980b-c1d2e5f93fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "#      gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "#     output = model(train_x)\n",
    "#     loss = -mll(output, train_y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bd172ab0-afce-439e-b40f-3cd6cb47f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a2e01b9-c073-473f-883d-22b03c135404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.509899\n",
      "R2 = 0.246527\n",
      "mse = 0.004746\n"
     ]
    }
   ],
   "source": [
    "# epistatic\n",
    "figure(figsize=(5, 5), dpi=80)\n",
    "plt.plot(f_mean, y_test, 'o', alpha=.3)\n",
    "plt.show()\n",
    "print('r2 = %f'%pearsonr(f_mean, y_test)[0]**2)\n",
    "print('R2 = %f'%r2(y_test, f_mean))\n",
    "print('mse = %f'%mse(f_mean, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02e1ecbb-0c11-4430-8bf5-76eff0b4036f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiGPModel(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): ConstantMean()\n",
       "  (covar_module): MultiDeviceKernel(\n",
       "    (module): DiKernel(\n",
       "      (raw_lda_constraint): LessThan(0.000E+00)\n",
       "      (raw_eta_constraint): LessThan(0.000E+00)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e1654a8-006a-4388-baea-ef387f36281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    N = train_x.size(0)\n",
    "\n",
    "    # Find the optimum partition/checkpoint size by decreasing in powers of 2\n",
    "    # Start with no partitioning (size = 0)\n",
    "    settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0da89791-7b3f-4d86-814c-d467ce5ff6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 50000, 25000, 12500, 6250, 3125, 1563, 782, 391, 196, 98, 49, 25, 13, 7, 4]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ea086f0-7525-4e75-9073-757d0eaeabd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 8 -- Kernel partition size: 0\n",
      "RuntimeError: Caught RuntimeError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\", line 398, in __call__\n",
      "    res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n",
      "  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/scratch/local/29645306/ipykernel_211166/934878869.py\", line 60, in forward\n",
      "    diff = d(x1, x2)\n",
      "  File \"/scratch/local/29645306/ipykernel_211166/3148871899.py\", line 17, in d\n",
      "    return torch.stack((S1, S2, D1, D2))\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 37.25 GiB (GPU 0; 79.35 GiB total capacity; 51.45 GiB already allocated; 25.71 GiB free; 51.82 GiB reserved in total by PyTorch)\n",
      "\n",
      "Number of devices: 8 -- Kernel partition size: 50000\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 25000\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 12500\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 6250\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 3125\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 1563\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 782\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 391\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 196\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 98\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 49\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 25\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 13\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 7\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 4\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 74.51 GiB (GPU 0; 79.35 GiB total capacity; 40.10 GiB already allocated; 37.43 GiB free; 40.10 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def find_best_gpu_setting(train_x,\n",
    "                          train_y,\n",
    "                          n_devices,\n",
    "                          output_device,\n",
    "                          preconditioner_size\n",
    "):\n",
    "    N = train_x.size(0)\n",
    "\n",
    "    # Find the optimum partition/checkpoint size by decreasing in powers of 2\n",
    "    # Start with no partitioning (size = 0)\n",
    "    settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]\n",
    "\n",
    "    for checkpoint_size in settings:\n",
    "        print('Number of devices: {} -- Kernel partition size: {}'.format(n_devices, checkpoint_size))\n",
    "        try:\n",
    "            # Try a full forward and backward pass with this setting to check memory usage\n",
    "            \n",
    "\n",
    "            with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "                 gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "                output = model(train_x)\n",
    "                loss = -mll(output, train_y)\n",
    "    \n",
    "            \n",
    "\n",
    "            # when successful, break out of for-loop and jump to finally block\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            print('RuntimeError: {}'.format(e))\n",
    "        except AttributeError as e:\n",
    "            print('AttributeError: {}'.format(e))\n",
    "        finally:\n",
    "            # handle CUDA OOM error\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return checkpoint_size\n",
    "\n",
    "# Set a large enough preconditioner size to reduce the number of CG iterations run\n",
    "preconditioner_size = 100\n",
    "checkpoint_size = find_best_gpu_setting(train_x, train_y,\n",
    "                                        n_devices=n_devices,\n",
    "                                        output_device=output_device,\n",
    "                                        preconditioner_size=preconditioner_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cc7da3f-8c1b-4f2c-880a-442b5f9a2f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52662bb5-2bbd-42c8-9423-4732f45fc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ea7573a-1df0-4b4a-93e7-aff7b2d3af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 95025,\n",
       " 47513,\n",
       " 23757,\n",
       " 11879,\n",
       " 5940,\n",
       " 2970,\n",
       " 1485,\n",
       " 743,\n",
       " 372,\n",
       " 186,\n",
       " 93,\n",
       " 47,\n",
       " 24,\n",
       " 12,\n",
       " 6,\n",
       " 3]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09198df-7aef-47d2-ab6c-20093d245c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
