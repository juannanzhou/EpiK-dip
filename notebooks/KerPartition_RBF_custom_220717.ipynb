{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee8fa84-c71b-493a-9c8d-4fa4b0829463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4ba6c4-554a-499a-9a57-831ce9fef021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def rl():\n",
    "    importlib.reload(Di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db4d4b5-112f-4432-b9e2-dfa948d538bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24019a9-b8e4-4e74-8ced-766c35628d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import binom as binom\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import Di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7795813-1684-49a8-b283-21acdb3a096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "output_device = 0\n",
    "n_devices = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca9b5f8a-9347-4381-bfa5-688016db6c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/42291897/ipykernel_48498/565950420.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  geno_t = torch.tensor(geno_t, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "geno_file_list = []\n",
    "for path, currentDirectory, files in os.walk(\"96ghpptzvf-4/SData2/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"geno.txt\"):\n",
    "            geno_file_list.append(file)\n",
    "\n",
    "geno_file_list = list(set(geno_file_list))\n",
    "\n",
    "env_list = [file.split('_')[0] for file in geno_file_list]\n",
    "\n",
    "env_list = sorted(env_list)\n",
    "\n",
    "env = env_list[5]\n",
    "\n",
    "df = pd.read_csv(\"96ghpptzvf-4/SData2/\"+ env + \"_geno.txt\", sep='\\t', nrows=5, engine='python')\n",
    "\n",
    "ids = list(df.columns[3:])\n",
    "\n",
    "env + '_matsui_geno_t.pt'\n",
    "\n",
    "geno_t = torch.load(env + '_matsui_geno_t.pt')\n",
    "\n",
    "geno_t = torch.tensor(geno_t, dtype=torch.float)\n",
    "\n",
    "geno_t = torch.transpose(geno_t, 0, 1)\n",
    "N, L = geno_t.shape\n",
    "\n",
    "# geno_t = geno_t[:, :5000]\n",
    "\n",
    "pheno = pd.read_csv(\"96ghpptzvf-4/SData6/\" + env + \"_pheno.txt\", sep='\\t', engine=\"python\")\n",
    "\n",
    "pheno = pheno.set_index('geno')\n",
    "\n",
    "pheno = pheno.loc[ids]\n",
    "\n",
    "inds_sub = np.where(np.array(pheno.pheno < -0.6) == False)[0]\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "sub = np.random.choice(inds_sub, 150000)\n",
    "\n",
    "sub_t = np.random.choice(list(set(inds_sub).difference(sub)), 5000)\n",
    "\n",
    "train_x = geno_t[sub]\n",
    "train_y = torch.tensor(np.array(pheno.pheno[sub]), dtype=torch.float32)\n",
    "\n",
    "test_x = geno_t[sub_t]\n",
    "test_y = torch.tensor(np.array(pheno.pheno[sub_t]), dtype=torch.float32)\n",
    "\n",
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "train_x, train_y = train_x.to(output_device), train_y.to(output_device)\n",
    "test_x, test_y = test_x.to(output_device), test_y.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ff0d866-5e5a-40bf-9911-ec8e3aba037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = train_x[:10]\n",
    "x2 = train_x[10:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05945-e264-4ef8-986e-16ae38cc5189",
   "metadata": {},
   "source": [
    "### Test kernel partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b30a6d-0ad1-4d7b-b0a2-8d8c3aca5ad8",
   "metadata": {},
   "source": [
    "#### Define kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2bd61c-75da-469f-9a33-07af622e6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch import lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69aaa8fc-43c4-407e-980d-390625a4520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(geno1, geno2):\n",
    "  \"\"\"build distance tensor between two sets of genotypes\n",
    "  geno1, geno2: n x L, m x L torch tensors\n",
    "  \n",
    "  \"\"\"\n",
    "  geno1_h0 = 1.*(geno1 == 0.)\n",
    "  geno1_h1 = 1.*(geno1 == 2.)\n",
    "  geno2_h0 = 1.*(geno2 == 0.)\n",
    "  geno2_h1 = 1.*(geno2 == 2.)\n",
    "  S1 = torch.matmul(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "  S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "  D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "        + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "  D1 = L - S1 - S2 - D2\n",
    "\n",
    "  return torch.stack((S1, S2, D1, D2))\n",
    "\n",
    "\n",
    "def k(log_lda, log_eta, dvec):\n",
    "    \"\"\"\n",
    "    log_lda, log_eta -- torch tensors\n",
    "    dvec -- 4 x n x m torch tensor\n",
    "    \"\"\"\n",
    "    lda = torch.exp(log_lda)\n",
    "    eta = torch.exp(log_eta)\n",
    "    return (((1 + lda + eta)**(dvec[1] - L/2))\n",
    "          *((1 - lda + eta)**dvec[3])\n",
    "          *((1 + eta)**(dvec[0] - L/2)) \n",
    "          * (1-eta)**dvec[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54fe4276-5210-470c-b6c5-92ac4dc7a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod = lazy.MatmulLazyTensor(train_x[:100], train_x[:100].transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c1deff-b68a-49fa-95f4-89139ddd529b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#   geno1_h0 = 1.*(geno1 == 0.)\n",
    "#   geno1_h1 = 1.*(geno1 == 2.)\n",
    "#   geno2_h0 = 1.*(geno2 == 0.)\n",
    "#   geno2_h1 = 1.*(geno2 == 2.)\n",
    "#   S1 = torch.matmul(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "#   S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "#         + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "#   D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "#         + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "#   D1 = L - S1 - S2 - D2\n",
    "#   return torch.stack((S1, S2, D1, D2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe708e1-26f2-4d2a-89e6-1eae5611a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinKernel(gpytorch.kernels.Kernel):\n",
    "#   \"\"\"\n",
    "#   Additive kernel\n",
    "#   no free parameters\n",
    "#   calculated using the D tensor\n",
    "#   \"\"\"\n",
    "\n",
    "#   is_stationary = True\n",
    "\n",
    "#   # We will register the parameter when initializing the kernel\n",
    "#   def __init__(self,\n",
    "#                 **kwargs):\n",
    "#       super().__init__(**kwargs)\n",
    "\n",
    "#   def forward(self, geno1, geno2, diag=False, **params):\n",
    "#         geno1_h0 = 1.*(geno1 == 0.)\n",
    "#         geno1_h1 = 1.*(geno1 == 2.)\n",
    "#         geno2_h0 = 1.*(geno2 == 0.)\n",
    "#         geno2_h1 = 1.*(geno2 == 2.)\n",
    "# #         S1 = lazy.MatmulLazyTensor(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "#         S2 = (lazy.MatmulLazyTensor(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "#             + lazy.MatmulLazyTensor(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "#         D2 = (lazy.MatmulLazyTensor(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "#             + lazy.MatmulLazyTensor(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "# #         prod = (1 + lda + eta)**(S2.evaluate() - L/2)\n",
    "#         K = S2 - D2\n",
    "\n",
    "\n",
    "\n",
    "#         return K.diag() if diag else K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6712767-54c6-47c8-9e46-2ae5edfeff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = torch.exp(torch.tensor(-8.))\n",
    "eta = torch.exp(torch.tensor(-12.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b98455-85e1-4169-b16d-a1514e753ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinKernel(gpytorch.kernels.Kernel):\n",
    "    \"\"\"\n",
    "    Additive kernel\n",
    "    no free parameters\n",
    "    calculated using the D tensor\n",
    "    \"\"\"\n",
    "\n",
    "    is_stationary = True\n",
    "\n",
    "  # We will register the parameter when initializing the kernel\n",
    "    def __init__(self,\n",
    "                **kwargs):\n",
    "      super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, geno1, geno2, diag=False, **params):\n",
    "#         geno1_h0 = 1.*(geno1 == 0.)\n",
    "#         geno1_h1 = 1.*(geno1 == 2.)\n",
    "#         geno2_h0 = 1.*(geno2 == 0.)\n",
    "#         geno2_h1 = 1.*(geno2 == 2.)\n",
    "#         S1 = torch.matmul(geno1%2, torch.transpose(geno2%2, 0, 1))\n",
    "#         S2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h0, 0, 1)) \n",
    "#             + torch.matmul(geno1_h1, torch.transpose(geno2_h1, 0, 1)))\n",
    "#         D2 = (torch.matmul(geno1_h0, torch.transpose(geno2_h1, 0, 1)) \n",
    "#             + torch.matmul(geno1_h1, torch.transpose(geno2_h0, 0, 1)))\n",
    "#         prod = (S1.div(L**2))\n",
    "#         prod = lda**S1\n",
    "\n",
    "#         prod = ((1 + lda + eta)**(S2 - L/2))*((1 - lda + eta)**D2)*((1 + eta)**(S1 - L/2))*(1-eta)**(L - S1 - S2 - D2)\n",
    "\n",
    "        diff = self.covar_dist(geno1, geno2, **params)\n",
    "        prod =  diff\n",
    "\n",
    "\n",
    "        return prod.diag() if diag else prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f5de10-05cb-47fe-83e7-1571bfdeb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch.kernels.kernel as kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a21514b9-96b7-4f60-8222-caf77f5b7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "class CosineKernel((gpytorch.kernels.Kernel)):\n",
    "\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, period_length_prior=None, period_length_constraint=None, **kwargs):\n",
    "        super(CosineKernel, self).__init__(**kwargs)\n",
    "\n",
    "        self.register_parameter(\n",
    "            name=\"raw_period_length\", parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        if period_length_constraint is None:\n",
    "            period_length_constraint = Positive()\n",
    "\n",
    "        if period_length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"period_length_prior\",\n",
    "                period_length_prior,\n",
    "                lambda m: m.period_length,\n",
    "                lambda m, v: m._set_period_length(v),\n",
    "            )\n",
    "\n",
    "        self.register_constraint(\"raw_period_length\", period_length_constraint)\n",
    "\n",
    "    @property\n",
    "    def period_length(self):\n",
    "        return self.raw_period_length_constraint.transform(self.raw_period_length)\n",
    "\n",
    "    @period_length.setter\n",
    "    def period_length(self, value):\n",
    "        return self._set_period_length(value)\n",
    "\n",
    "    def _set_period_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_period_length)\n",
    "\n",
    "        self.initialize(raw_period_length=self.raw_period_length_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        x1_ = x1\n",
    "        x2_ = x2\n",
    "        diff = x1_.matmul(x2_.t())\n",
    "#         diff = self.covar_dist(x1_, x2_, **params)\n",
    "        res = torch.exp(-.01*diff)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2d6f1e7-a3cd-435b-8286-5328bbd2fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ker = CosineKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3eee1cf-9bf9-41a6-8289-3c02c4ec9713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 2.9989e-38, 1.4129e-37, 1.4848e-33, 2.4663e-32, 0.0000e+00,\n",
       "         5.4502e-37, 1.4013e-45, 8.1336e-41, 4.2666e-39],\n",
       "        [2.9989e-38, 0.0000e+00, 5.7872e-37, 1.8550e-34, 1.2588e-31, 4.0638e-44,\n",
       "         1.5807e-34, 2.7827e-40, 2.4984e-37, 7.0685e-37],\n",
       "        [1.4129e-37, 5.7872e-37, 0.0000e+00, 9.4221e-36, 2.2374e-33, 1.5204e-42,\n",
       "         1.6373e-36, 1.4239e-40, 3.3068e-41, 1.1920e-37],\n",
       "        [1.4848e-33, 1.8550e-34, 9.4221e-36, 0.0000e+00, 1.9004e-24, 5.7892e-41,\n",
       "         6.9262e-33, 7.1556e-34, 5.0572e-39, 2.8590e-35],\n",
       "        [2.4663e-32, 1.2588e-31, 2.2374e-33, 1.9004e-24, 2.4803e-43, 7.6177e-35,\n",
       "         6.8573e-33, 4.0467e-34, 6.8928e-35, 1.2527e-33],\n",
       "        [0.0000e+00, 4.0638e-44, 1.5204e-42, 5.7892e-41, 7.6177e-35, 0.0000e+00,\n",
       "         4.0091e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [5.4502e-37, 1.5807e-34, 1.6373e-36, 6.9262e-33, 6.8573e-33, 4.0091e-42,\n",
       "         0.0000e+00, 5.9923e-35, 1.5425e-40, 3.2496e-42],\n",
       "        [1.4013e-45, 2.7827e-40, 1.4239e-40, 7.1556e-34, 4.0467e-34, 0.0000e+00,\n",
       "         5.9923e-35, 0.0000e+00, 6.0860e-41, 2.0206e-40],\n",
       "        [8.1336e-41, 2.4984e-37, 3.3068e-41, 5.0572e-39, 6.8928e-35, 0.0000e+00,\n",
       "         1.5425e-40, 6.0860e-41, 0.0000e+00, 5.1345e-41],\n",
       "        [4.2666e-39, 7.0685e-37, 1.1920e-37, 2.8590e-35, 1.2527e-33, 0.0000e+00,\n",
       "         3.2496e-42, 2.0206e-40, 5.1345e-41, 0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ker(x1, x1).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dfa756e-fe71-483e-8dab-6d7759e6800c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, n_devices):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        base_covar_module = ker\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f8b960d-9b8e-47b4-a89c-5c2bc59cdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(output_device)\n",
    "\n",
    "model = ExactGPModel(train_x, train_y, likelihood, n_devices)\n",
    "# model.covar_module.module.raw_lda = torch.nn.Parameter(torch.tensor(-8.))\n",
    "# model.covar_module.module.raw_eta = torch.nn.Parameter(torch.tensor(-12.))\n",
    "model = model.to(output_device)\n",
    "# model = model.to(output_device).double()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), .02)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a23c9c79-dd00-43c9-bfc3-c4cce83b554a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 83.82 GiB (GPU 0; 79.35 GiB total capacity; 12.23 GiB already allocated; 52.38 GiB free; 25.11 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/42291897/ipykernel_48498/45299037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_preconditioner_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreconditioner_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvQuadLogDet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         inv_quad_term, logdet_term = func(\n\u001b[0m\u001b[1;32m   1283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_quad_log_det.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, dtype, device, matrix_shape, batch_shape, inv_quad, logdet, probe_vectors, probe_vector_norms, *args)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlazy_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmatrix_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecond_lt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet_correction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreconditioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_preconditioner_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/pivoted_cholesky.py\u001b[0m in \u001b[0;36mpivoted_cholesky\u001b[0;34m(matrix, max_iter, error_tol)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# LazyTensor.diag() operates in batch mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmatrix_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_approx_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Make sure max_iter isn't bigger than the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_approx_diag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdiagonal\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdiagonals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cholesky\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         res = super(Kernel, self.kernel).__call__(\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/42291897/ipykernel_48498/2985257221.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx1_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx2_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;31m#         diff = self.covar_dist(x1_, x2_, **params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 83.82 GiB (GPU 0; 79.35 GiB total capacity; 12.23 GiB already allocated; 52.38 GiB free; 25.11 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "checkpoint_size = train_x.shape[0]//2\n",
    "preconditioner_size = 100\n",
    "\n",
    "with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "     gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.zero_grad()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f09bc-3cf6-4632-9752-7d227625593b",
   "metadata": {},
   "source": [
    "#### Find checkpoint_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6d4ccf8-b8a1-4c54-b977-7328e7b38564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = train_x.size(0)\n",
    "\n",
    "# Find the optimum partition/checkpoint size by decreasing in powers of 2\n",
    "# Start with no partitioning (size = 0)\n",
    "settings = [0] + [int(n) for n in np.ceil(N / 2**np.arange(1, np.floor(np.log2(N))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57da8552-5782-41bc-b48b-63d8e9386422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings = settings[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea086f0-7525-4e75-9073-757d0eaeabd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 8 -- Kernel partition size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:234: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.sum(mul_storage, -2, keepdim=True, out=alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: CUDA out of memory. Tried to allocate 10.48 GiB (GPU 0; 79.35 GiB total capacity; 62.46 GiB already allocated; 4.32 GiB free; 73.17 GiB reserved in total by PyTorch)\n",
      "Number of devices: 8 -- Kernel partition size: 75000\n",
      "final checkpoint_size = 75000\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def find_best_gpu_setting(train_x,\n",
    "                          train_y,\n",
    "                          n_devices,\n",
    "                          output_device,\n",
    "                          preconditioner_size\n",
    "):\n",
    "\n",
    "    for checkpoint_size in settings:\n",
    "        print('Number of devices: {} -- Kernel partition size: {}'.format(n_devices, checkpoint_size))\n",
    "        try:\n",
    "            # Try a full forward and backward pass with this setting to check memory usage\n",
    "            \n",
    "\n",
    "            with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "                 gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "                output = model(train_x)\n",
    "                loss = -mll(output, train_y)\n",
    "                loss.backward()\n",
    "                optimizer.zero_grad()\n",
    "                optimizer.step()\n",
    "    \n",
    "            \n",
    "\n",
    "            # when successful, break out of for-loop and jump to finally block\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            print('RuntimeError: {}'.format(e))\n",
    "        except AttributeError as e:\n",
    "            print('AttributeError: {}'.format(e))\n",
    "        finally:\n",
    "            # handle CUDA OOM error\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    return checkpoint_size\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Set a large enough preconditioner size to reduce the number of CG iterations run\n",
    "preconditioner_size = 100\n",
    "checkpoint_size = find_best_gpu_setting(train_x, train_y,\n",
    "                                        n_devices=n_devices,\n",
    "                                        output_device=output_device,\n",
    "                                        preconditioner_size=preconditioner_size)\n",
    "print(\"final checkpoint_size = %s\" %checkpoint_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2df42084-a687-44bc-a948-067b067a62ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 39% |\n",
      "|  1 |  0% | 21% |\n",
      "|  2 |  0% | 21% |\n",
      "|  3 |  0% | 21% |\n",
      "|  4 |  0% | 21% |\n",
      "|  5 |  0% | 21% |\n",
      "|  6 |  0% | 21% |\n",
      "|  7 |  0% | 21% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b5ab2c0-4321-4e19-b65f-061eb2353b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_part(train_x,train_y,n_devices,output_device,preconditioner_size):\n",
    "#     with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "#          gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "#         output = model(train_x)\n",
    "#         loss = -mll(output, train_y)\n",
    "#     return loss\n",
    "\n",
    "# checkpoint_size = checkpoint_size\n",
    "# preconditioner_size = 100\n",
    "\n",
    "# test_part(train_x, train_y, n_devices=n_devices, output_device=output_device, preconditioner_size=preconditioner_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522d6ac-751a-4d66-9fe0-c906ad32ffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167123f-3de9-4995-9fd7-6ab1c79aecb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14edcd31-3f25-4758-bbb8-a0b9ce4ea05a",
   "metadata": {},
   "source": [
    "### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "880d906f-0a77-4675-8a48-1e86a69a7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                likelihood, \n",
    "                train_x, \n",
    "                train_y, \n",
    "                checkpoint_size, \n",
    "                preconditioner_size, \n",
    "                training_iter=300, \n",
    "                lr=.05):\n",
    "    losses = []\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    \n",
    "    for i in range(training_iter):\n",
    "        print(i)\n",
    "        with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "             gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()  \n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b0832e2-b7f1-4693-9420-3c4adacf23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=.1)\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "optimizer.zero_grad()\n",
    "# Output from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4af7d7f7-4686-448e-b9a8-f3d529f80c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_size = train_x.shape[0]//2\n",
    "checkpoint_size = 0\n",
    "preconditioner_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bc9fac8-06be-4671-b3da-812a972993f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:234: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.sum(mul_storage, -2, keepdim=True, out=alpha)\n"
     ]
    }
   ],
   "source": [
    "with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "     gpytorch.settings.max_preconditioner_size(preconditioner_size):\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()  \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c675d7e1-9f1d-4d12-b7ce-49d975fc730e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\", line 398, in __call__\n    res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\n    outputs = self.forward(*inputs, **kwargs)\n  File \"/blue/juannanzhou/matsui_data/Di.py\", line 136, in forward\n    diff = d(x1, x2)\n  File \"/blue/juannanzhou/matsui_data/Di.py\", line 39, in d\n    return torch.stack((S1, S2, D1, D2))\nRuntimeError: CUDA out of memory. Tried to allocate 18.63 GiB (GPU 0; 79.35 GiB total capacity; 38.36 GiB already allocated; 16.23 GiB free; 61.25 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/42117759/ipykernel_142134/112040142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m losses = train_model(model, \n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mcheckpoint_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/42117759/ipykernel_142134/3399368535.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, likelihood, train_x, train_y, checkpoint_size, preconditioner_size, training_iter, lr)\u001b[0m\n\u001b[1;32m     16\u001b[0m              \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_preconditioner_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreconditioner_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mIn\u001b[0m \u001b[0mparticular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar1\u001b[0m \u001b[0mwould\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0malways\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mAddedDiagLazyTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mcovar2\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0madded_diag_lazy_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madded_diag_lazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madded_diag_lazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mrepresentation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0mincluding\u001b[0m \u001b[0mall\u001b[0m \u001b[0msubobjects\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minternally\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \"\"\"\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLazyTensorRepresentationTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lazy_tsr)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"representation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is it a lazy tensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mrepresentation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mtemp_active_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# TODO: parallel_apply might be too heavyweight in some cases?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazily_evaluate_kernels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\", line 398, in __call__\n    res = lazify(super(Kernel, self).__call__(x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n  File \"/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/module.py\", line 30, in __call__\n    outputs = self.forward(*inputs, **kwargs)\n  File \"/blue/juannanzhou/matsui_data/Di.py\", line 136, in forward\n    diff = d(x1, x2)\n  File \"/blue/juannanzhou/matsui_data/Di.py\", line 39, in d\n    return torch.stack((S1, S2, D1, D2))\nRuntimeError: CUDA out of memory. Tried to allocate 18.63 GiB (GPU 0; 79.35 GiB total capacity; 38.36 GiB already allocated; 16.23 GiB free; 61.25 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "losses = train_model(model, \n",
    "                likelihood, \n",
    "                train_x, \n",
    "                train_y, \n",
    "                checkpoint_size, \n",
    "                preconditioner_size, \n",
    "                training_iter=5, \n",
    "                lr=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cbf2916-93b0-4091-a0c2-add00ec04df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood.noise_covar.raw_noise tensor([-2.4149], device='cuda:0')\n",
      "mean_module.constant tensor([0.5239], device='cuda:0')\n",
      "covar_module.module.raw_outputscale tensor(-2.3764, device='cuda:0')\n",
      "covar_module.module.base_kernel.raw_lengthscale tensor([[2.3349]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1616de8a-7163-4519-b337-c428bb9e8dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 60% |\n",
      "|  1 |  0% | 48% |\n",
      "|  2 |  0% | 48% |\n",
      "|  3 |  0% | 48% |\n",
      "|  4 |  0% | 48% |\n",
      "|  5 |  0% | 48% |\n",
      "|  6 |  0% | 48% |\n",
      "|  7 |  0% | 48% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79020eaa-168a-4d1b-9d52-8cc8f0fe6a03",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f24f0b8-e82d-4f04-bb8b-e71080452cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.001976\n",
      "R2 = -182.358695\n",
      "mse = 1.601331\n"
     ]
    }
   ],
   "source": [
    "preconditioner_size = 100\n",
    "# checkpoint_size = checkpoint_size=train_x.shape[0]//2\n",
    "\n",
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.beta_features.checkpoint_kernel(checkpoint_size):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n",
    "\n",
    "\n",
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()\n",
    "\n",
    "# epistatic\n",
    "figure(figsize=(5, 5), dpi=80)\n",
    "plt.plot(f_mean, y_test, 'o', alpha=.3)\n",
    "plt.show()\n",
    "print('r2 = %f'%pearsonr(f_mean, y_test)[0]**2)\n",
    "print('R2 = %f'%r2(y_test, f_mean))\n",
    "print('mse = %f'%mse(f_mean, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b98392-96c2-4035-8cdf-7309516a9c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f39875c-44c2-4e6a-81b7-8168f87d45a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from copy import deepcopy\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def is_legal(v):\n",
    "    \"\"\"\n",
    "    Checks that tensor is not NaN or Inf.\n",
    "\n",
    "    Inputs:\n",
    "        v (tensor): tensor to be checked\n",
    "\n",
    "    \"\"\"\n",
    "    legal = not torch.isnan(v).any() and not torch.isinf(v)\n",
    "\n",
    "    return legal\n",
    "\n",
    "\n",
    "def polyinterp(points, x_min_bound=None, x_max_bound=None, plot=False):\n",
    "    \"\"\"\n",
    "    Gives the minimizer and minimum of the interpolating polynomial over given points\n",
    "    based on function and derivative information. Defaults to bisection if no critical\n",
    "    points are valid.\n",
    "\n",
    "    Based on polyinterp.m Matlab function in minFunc by Mark Schmidt with some slight\n",
    "    modifications.\n",
    "\n",
    "    Implemented by: Hao-Jun Michael Shi and Dheevatsa Mudigere\n",
    "    Last edited 12/6/18.\n",
    "\n",
    "    Inputs:\n",
    "        points (nparray): two-dimensional array with each point of form [x f g]\n",
    "        x_min_bound (float): minimum value that brackets minimum (default: minimum of points)\n",
    "        x_max_bound (float): maximum value that brackets minimum (default: maximum of points)\n",
    "        plot (bool): plot interpolating polynomial\n",
    "\n",
    "    Outputs:\n",
    "        x_sol (float): minimizer of interpolating polynomial\n",
    "        F_min (float): minimum of interpolating polynomial\n",
    "\n",
    "    Note:\n",
    "      . Set f or g to np.nan if they are unknown\n",
    "\n",
    "    \"\"\"\n",
    "    no_points = points.shape[0]\n",
    "    order = np.sum(1 - np.isnan(points[:, 1:3]).astype('int')) - 1\n",
    "\n",
    "    x_min = np.min(points[:, 0])\n",
    "    x_max = np.max(points[:, 0])\n",
    "\n",
    "    # compute bounds of interpolation area\n",
    "    if x_min_bound is None:\n",
    "        x_min_bound = x_min\n",
    "    if x_max_bound is None:\n",
    "        x_max_bound = x_max\n",
    "\n",
    "    # explicit formula for quadratic interpolation\n",
    "    if no_points == 2 and order == 2 and plot is False:\n",
    "        # Solution to quadratic interpolation is given by:\n",
    "        # a = -(f1 - f2 - g1(x1 - x2))/(x1 - x2)^2\n",
    "        # x_min = x1 - g1/(2a)\n",
    "        # if x1 = 0, then is given by:\n",
    "        # x_min = - (g1*x2^2)/(2(f2 - f1 - g1*x2))\n",
    "\n",
    "        if points[0, 0] == 0:\n",
    "            x_sol = -points[0, 2] * points[1, 0] ** 2 / (2 * (points[1, 1] - points[0, 1] - points[0, 2] * points[1, 0]))\n",
    "        else:\n",
    "            a = -(points[0, 1] - points[1, 1] - points[0, 2] * (points[0, 0] - points[1, 0])) / (points[0, 0] - points[1, 0]) ** 2\n",
    "            x_sol = points[0, 0] - points[0, 2]/(2*a)\n",
    "\n",
    "        x_sol = np.minimum(np.maximum(x_min_bound, x_sol), x_max_bound)\n",
    "\n",
    "    # explicit formula for cubic interpolation\n",
    "    elif no_points == 2 and order == 3 and plot is False:\n",
    "        # Solution to cubic interpolation is given by:\n",
    "        # d1 = g1 + g2 - 3((f1 - f2)/(x1 - x2))\n",
    "        # d2 = sqrt(d1^2 - g1*g2)\n",
    "        # x_min = x2 - (x2 - x1)*((g2 + d2 - d1)/(g2 - g1 + 2*d2))\n",
    "        d1 = points[0, 2] + points[1, 2] - 3 * ((points[0, 1] - points[1, 1]) / (points[0, 0] - points[1, 0]))\n",
    "        d2 = np.sqrt(d1 ** 2 - points[0, 2] * points[1, 2])\n",
    "        if np.isreal(d2):\n",
    "            x_sol = points[1, 0] - (points[1, 0] - points[0, 0]) * ((points[1, 2] + d2 - d1) / (points[1, 2] - points[0, 2] + 2 * d2))\n",
    "            x_sol = np.minimum(np.maximum(x_min_bound, x_sol), x_max_bound)\n",
    "        else:\n",
    "            x_sol = (x_max_bound + x_min_bound)/2\n",
    "\n",
    "    # solve linear system\n",
    "    else:\n",
    "        # define linear constraints\n",
    "        A = np.zeros((0, order + 1))\n",
    "        b = np.zeros((0, 1))\n",
    "\n",
    "        # add linear constraints on function values\n",
    "        for i in range(no_points):\n",
    "            if not np.isnan(points[i, 1]):\n",
    "                constraint = np.zeros((1, order + 1))\n",
    "                for j in range(order, -1, -1):\n",
    "                    constraint[0, order - j] = points[i, 0] ** j\n",
    "                A = np.append(A, constraint, 0)\n",
    "                b = np.append(b, points[i, 1])\n",
    "\n",
    "        # add linear constraints on gradient values\n",
    "        for i in range(no_points):\n",
    "            if not np.isnan(points[i, 2]):\n",
    "                constraint = np.zeros((1, order + 1))\n",
    "                for j in range(order):\n",
    "                    constraint[0, j] = (order - j) * points[i, 0] ** (order - j - 1)\n",
    "                A = np.append(A, constraint, 0)\n",
    "                b = np.append(b, points[i, 2])\n",
    "\n",
    "        # check if system is solvable\n",
    "        if A.shape[0] != A.shape[1] or np.linalg.matrix_rank(A) != A.shape[0]:\n",
    "            x_sol = (x_min_bound + x_max_bound)/2\n",
    "            f_min = np.Inf\n",
    "        else:\n",
    "            # solve linear system for interpolating polynomial\n",
    "            coeff = np.linalg.solve(A, b)\n",
    "\n",
    "            # compute critical points\n",
    "            dcoeff = np.zeros(order)\n",
    "            for i in range(len(coeff) - 1):\n",
    "                dcoeff[i] = coeff[i] * (order - i)\n",
    "\n",
    "            crit_pts = np.array([x_min_bound, x_max_bound])\n",
    "            crit_pts = np.append(crit_pts, points[:, 0])\n",
    "\n",
    "            if not np.isinf(dcoeff).any():\n",
    "                roots = np.roots(dcoeff)\n",
    "                crit_pts = np.append(crit_pts, roots)\n",
    "\n",
    "            # test critical points\n",
    "            f_min = np.Inf\n",
    "            x_sol = (x_min_bound + x_max_bound) / 2 # defaults to bisection\n",
    "            for crit_pt in crit_pts:\n",
    "                if np.isreal(crit_pt) and crit_pt >= x_min_bound and crit_pt <= x_max_bound:\n",
    "                    F_cp = np.polyval(coeff, crit_pt)\n",
    "                    if np.isreal(F_cp) and F_cp < f_min:\n",
    "                        x_sol = np.real(crit_pt)\n",
    "                        f_min = np.real(F_cp)\n",
    "\n",
    "            if(plot):\n",
    "                plt.figure()\n",
    "                x = np.arange(x_min_bound, x_max_bound, (x_max_bound - x_min_bound)/10000)\n",
    "                f = np.polyval(coeff, x)\n",
    "                plt.plot(x, f)\n",
    "                plt.plot(x_sol, f_min, 'x')\n",
    "\n",
    "    return x_sol\n",
    "\n",
    "\n",
    "class LBFGS(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements the L-BFGS algorithm. Compatible with multi-batch and full-overlap\n",
    "    L-BFGS implementations and (stochastic) Powell damping. Partly based on the \n",
    "    original L-BFGS implementation in PyTorch, Mark Schmidt's minFunc MATLAB code, \n",
    "    and Michael Overton's weak Wolfe line search MATLAB code.\n",
    "\n",
    "    Implemented by: Hao-Jun Michael Shi and Dheevatsa Mudigere\n",
    "    Last edited 10/20/20.\n",
    "\n",
    "    Warnings:\n",
    "      . Does not support per-parameter options and parameter groups.\n",
    "      . All parameters have to be on a single device.\n",
    "\n",
    "    Inputs:\n",
    "        lr (float): steplength or learning rate (default: 1)\n",
    "        history_size (int): update history size (default: 10)\n",
    "        line_search (str): designates line search to use (default: 'Wolfe')\n",
    "            Options:\n",
    "                'None': uses steplength designated in algorithm\n",
    "                'Armijo': uses Armijo backtracking line search\n",
    "                'Wolfe': uses Armijo-Wolfe bracketing line search\n",
    "        dtype: data type (default: torch.float)\n",
    "        debug (bool): debugging mode\n",
    "\n",
    "    References:\n",
    "    [1] Berahas, Albert S., Jorge Nocedal, and Martin Takác. \"A Multi-Batch L-BFGS \n",
    "        Method for Machine Learning.\" Advances in Neural Information Processing \n",
    "        Systems. 2016.\n",
    "    [2] Bollapragada, Raghu, et al. \"A Progressive Batching L-BFGS Method for Machine \n",
    "        Learning.\" International Conference on Machine Learning. 2018.\n",
    "    [3] Lewis, Adrian S., and Michael L. Overton. \"Nonsmooth Optimization via Quasi-Newton\n",
    "        Methods.\" Mathematical Programming 141.1-2 (2013): 135-163.\n",
    "    [4] Liu, Dong C., and Jorge Nocedal. \"On the Limited Memory BFGS Method for \n",
    "        Large Scale Optimization.\" Mathematical Programming 45.1-3 (1989): 503-528.\n",
    "    [5] Nocedal, Jorge. \"Updating Quasi-Newton Matrices With Limited Storage.\" \n",
    "        Mathematics of Computation 35.151 (1980): 773-782.\n",
    "    [6] Nocedal, Jorge, and Stephen J. Wright. \"Numerical Optimization.\" Springer New York,\n",
    "        2006.\n",
    "    [7] Schmidt, Mark. \"minFunc: Unconstrained Differentiable Multivariate Optimization \n",
    "        in Matlab.\" Software available at http://www.cs.ubc.ca/~schmidtm/Software/minFunc.html \n",
    "        (2005).\n",
    "    [8] Schraudolph, Nicol N., Jin Yu, and Simon Günter. \"A Stochastic Quasi-Newton \n",
    "        Method for Online Convex Optimization.\" Artificial Intelligence and Statistics. \n",
    "        2007.\n",
    "    [9] Wang, Xiao, et al. \"Stochastic Quasi-Newton Methods for Nonconvex Stochastic \n",
    "        Optimization.\" SIAM Journal on Optimization 27.2 (2017): 927-956.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1., history_size=10, line_search='Wolfe',\n",
    "                 dtype=torch.float, debug=False):\n",
    "\n",
    "        # ensure inputs are valid\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0 <= history_size:\n",
    "            raise ValueError(\"Invalid history size: {}\".format(history_size))\n",
    "        if line_search not in ['Armijo', 'Wolfe', 'None']:\n",
    "            raise ValueError(\"Invalid line search: {}\".format(line_search))\n",
    "\n",
    "        defaults = dict(lr=lr, history_size=history_size, line_search=line_search, dtype=dtype, debug=debug)\n",
    "        super(LBFGS, self).__init__(params, defaults)\n",
    "\n",
    "        if len(self.param_groups) != 1:\n",
    "            raise ValueError(\"L-BFGS doesn't support per-parameter options \"\n",
    "                             \"(parameter groups)\")\n",
    "\n",
    "        self._params = self.param_groups[0]['params']\n",
    "        self._numel_cache = None\n",
    "\n",
    "        state = self.state['global_state']\n",
    "        state.setdefault('n_iter', 0)\n",
    "        state.setdefault('curv_skips', 0)\n",
    "        state.setdefault('fail_skips', 0)\n",
    "        state.setdefault('H_diag',1)\n",
    "        state.setdefault('fail', True)\n",
    "\n",
    "        state['old_dirs'] = []\n",
    "        state['old_stps'] = []\n",
    "\n",
    "    def _numel(self):\n",
    "        if self._numel_cache is None:\n",
    "            self._numel_cache = reduce(lambda total, p: total + p.numel(), self._params, 0)\n",
    "        return self._numel_cache\n",
    "\n",
    "    def _gather_flat_grad(self):\n",
    "        views = []\n",
    "        for p in self._params:\n",
    "            if p.grad is None:\n",
    "                view = p.data.new(p.data.numel()).zero_()\n",
    "            elif p.grad.data.is_sparse:\n",
    "                view = p.grad.data.to_dense().view(-1)\n",
    "            else:\n",
    "                view = p.grad.data.view(-1)\n",
    "            views.append(view)\n",
    "        return torch.cat(views, 0)\n",
    "\n",
    "    def _add_update(self, step_size, update):\n",
    "        offset = 0\n",
    "        for p in self._params:\n",
    "            numel = p.numel()\n",
    "            # view as to avoid deprecated pointwise semantics\n",
    "            p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n",
    "            offset += numel\n",
    "        assert offset == self._numel()\n",
    "\n",
    "    def _copy_params(self):\n",
    "        current_params = []\n",
    "        for param in self._params:\n",
    "            current_params.append(deepcopy(param.data))\n",
    "        return current_params\n",
    "\n",
    "    def _load_params(self, current_params):\n",
    "        i = 0\n",
    "        for param in self._params:\n",
    "            param.data[:] = current_params[i]\n",
    "            i += 1\n",
    "\n",
    "    def line_search(self, line_search):\n",
    "        \"\"\"\n",
    "        Switches line search option.\n",
    "        \n",
    "        Inputs:\n",
    "            line_search (str): designates line search to use\n",
    "                Options:\n",
    "                    'None': uses steplength designated in algorithm\n",
    "                    'Armijo': uses Armijo backtracking line search\n",
    "                    'Wolfe': uses Armijo-Wolfe bracketing line search\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        group = self.param_groups[0]\n",
    "        group['line_search'] = line_search\n",
    "        \n",
    "        return\n",
    "\n",
    "    def two_loop_recursion(self, vec):\n",
    "        \"\"\"\n",
    "        Performs two-loop recursion on given vector to obtain Hv.\n",
    "\n",
    "        Inputs:\n",
    "            vec (tensor): 1-D tensor to apply two-loop recursion to\n",
    "\n",
    "        Output:\n",
    "            r (tensor): matrix-vector product Hv\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        group = self.param_groups[0]\n",
    "        history_size = group['history_size']\n",
    "\n",
    "        state = self.state['global_state']\n",
    "        old_dirs = state.get('old_dirs')    # change in gradients\n",
    "        old_stps = state.get('old_stps')    # change in iterates\n",
    "        H_diag = state.get('H_diag')\n",
    "\n",
    "        # compute the product of the inverse Hessian approximation and the gradient\n",
    "        num_old = len(old_dirs)\n",
    "\n",
    "        if 'rho' not in state:\n",
    "            state['rho'] = [None] * history_size\n",
    "            state['alpha'] = [None] * history_size\n",
    "        rho = state['rho']\n",
    "        alpha = state['alpha']\n",
    "\n",
    "        for i in range(num_old):\n",
    "            rho[i] = 1. / old_stps[i].dot(old_dirs[i])\n",
    "\n",
    "        q = vec\n",
    "        for i in range(num_old - 1, -1, -1):\n",
    "            alpha[i] = old_dirs[i].dot(q) * rho[i]\n",
    "            q.add_(-alpha[i], old_stps[i])\n",
    "\n",
    "        # multiply by initial Hessian \n",
    "        # r/d is the final direction\n",
    "        r = torch.mul(q, H_diag)\n",
    "        for i in range(num_old):\n",
    "            beta = old_stps[i].dot(r) * rho[i]\n",
    "            r.add_(alpha[i] - beta, old_dirs[i])\n",
    "\n",
    "        return r\n",
    "\n",
    "    def curvature_update(self, flat_grad, eps=1e-2, damping=False):\n",
    "        \"\"\"\n",
    "        Performs curvature update.\n",
    "\n",
    "        Inputs:\n",
    "            flat_grad (tensor): 1-D tensor of flattened gradient for computing \n",
    "                gradient difference with previously stored gradient\n",
    "            eps (float): constant for curvature pair rejection or damping (default: 1e-2)\n",
    "            damping (bool): flag for using Powell damping (default: False)\n",
    "        \"\"\"\n",
    "\n",
    "        assert len(self.param_groups) == 1\n",
    "\n",
    "        # load parameters\n",
    "        if(eps <= 0):\n",
    "            raise(ValueError('Invalid eps; must be positive.'))\n",
    "\n",
    "        group = self.param_groups[0]\n",
    "        history_size = group['history_size']\n",
    "        debug = group['debug']\n",
    "\n",
    "        # variables cached in state (for tracing)\n",
    "        state = self.state['global_state']\n",
    "        fail = state.get('fail')\n",
    "        \n",
    "        # check if line search failed\n",
    "        if not fail:\n",
    "            \n",
    "            d = state.get('d')\n",
    "            t = state.get('t')\n",
    "            old_dirs = state.get('old_dirs')\n",
    "            old_stps = state.get('old_stps')\n",
    "            H_diag = state.get('H_diag')\n",
    "            prev_flat_grad = state.get('prev_flat_grad')\n",
    "            Bs = state.get('Bs')\n",
    "    \n",
    "            # compute y's\n",
    "            y = flat_grad.sub(prev_flat_grad)\n",
    "            s = d.mul(t)\n",
    "            sBs = s.dot(Bs)\n",
    "            ys = y.dot(s)  # y*s\n",
    "\n",
    "            # update L-BFGS matrix\n",
    "            if ys > eps * sBs or damping == True:\n",
    "    \n",
    "                # perform Powell damping\n",
    "                if damping == True and ys < eps*sBs:\n",
    "                    if debug:\n",
    "                        print('Applying Powell damping...')\n",
    "                    theta = ((1 - eps) * sBs)/(sBs - ys)\n",
    "                    y = theta * y + (1 - theta) * Bs\n",
    "    \n",
    "                # updating memory\n",
    "                if len(old_dirs) == history_size:\n",
    "                    # shift history by one (limited-memory)\n",
    "                    old_dirs.pop(0)\n",
    "                    old_stps.pop(0)\n",
    "    \n",
    "                # store new direction/step\n",
    "                old_dirs.append(s)\n",
    "                old_stps.append(y)\n",
    "    \n",
    "                # update scale of initial Hessian approximation\n",
    "                H_diag = ys / y.dot(y)  # (y*y)\n",
    "                \n",
    "                state['old_dirs'] = old_dirs\n",
    "                state['old_stps'] = old_stps\n",
    "                state['H_diag'] = H_diag\n",
    "\n",
    "            else:\n",
    "                # save skip\n",
    "                state['curv_skips'] += 1\n",
    "                if debug:\n",
    "                    print('Curvature pair skipped due to failed criterion')\n",
    "\n",
    "        else:\n",
    "            # save skip\n",
    "            state['fail_skips'] += 1\n",
    "            if debug:\n",
    "                print('Line search failed; curvature pair update skipped')\n",
    "\n",
    "        return\n",
    "\n",
    "    def _step(self, p_k, g_Ok, g_Sk=None, options=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        Inputs:\n",
    "            p_k (tensor): 1-D tensor specifying search direction\n",
    "            g_Ok (tensor): 1-D tensor of flattened gradient over overlap O_k used\n",
    "                            for gradient differencing in curvature pair update\n",
    "            g_Sk (tensor): 1-D tensor of flattened gradient over full sample S_k\n",
    "                            used for curvature pair damping or rejection criterion,\n",
    "                            if None, will use g_Ok (default: None)\n",
    "            options (dict): contains options for performing line search (default: None)\n",
    "\n",
    "        Options for Armijo backtracking line search:\n",
    "            'closure' (callable): reevaluates model and returns function value\n",
    "            'current_loss' (tensor): objective value at current iterate (default: F(x_k))\n",
    "            'gtd' (tensor): inner product g_Ok'd in line search (default: g_Ok'd)\n",
    "            'eta' (tensor): factor for decreasing steplength > 0 (default: 2)\n",
    "            'c1' (tensor): sufficient decrease constant in (0, 1) (default: 1e-4)\n",
    "            'max_ls' (int): maximum number of line search steps permitted (default: 10)\n",
    "            'interpolate' (bool): flag for using interpolation (default: True)\n",
    "            'inplace' (bool): flag for inplace operations (default: True)\n",
    "            'ls_debug' (bool): debugging mode for line search\n",
    "\n",
    "        Options for Wolfe line search:\n",
    "            'closure' (callable): reevaluates model and returns function value\n",
    "            'current_loss' (tensor): objective value at current iterate (default: F(x_k))\n",
    "            'gtd' (tensor): inner product g_Ok'd in line search (default: g_Ok'd)\n",
    "            'eta' (float): factor for extrapolation (default: 2)\n",
    "            'c1' (float): sufficient decrease constant in (0, 1) (default: 1e-4)\n",
    "            'c2' (float): curvature condition constant in (0, 1) (default: 0.9)\n",
    "            'max_ls' (int): maximum number of line search steps permitted (default: 10)\n",
    "            'interpolate' (bool): flag for using interpolation (default: True)\n",
    "            'inplace' (bool): flag for inplace operations (default: True)\n",
    "            'ls_debug' (bool): debugging mode for line search\n",
    "\n",
    "        Outputs (depends on line search):\n",
    "          . No line search:\n",
    "                t (float): steplength\n",
    "          . Armijo backtracking line search:\n",
    "                F_new (tensor): loss function at new iterate\n",
    "                t (tensor): final steplength\n",
    "                ls_step (int): number of backtracks\n",
    "                closure_eval (int): number of closure evaluations\n",
    "                desc_dir (bool): descent direction flag\n",
    "                    True: p_k is descent direction with respect to the line search\n",
    "                    function\n",
    "                    False: p_k is not a descent direction with respect to the line\n",
    "                    search function\n",
    "                fail (bool): failure flag\n",
    "                    True: line search reached maximum number of iterations, failed\n",
    "                    False: line search succeeded\n",
    "          . Wolfe line search:\n",
    "                F_new (tensor): loss function at new iterate\n",
    "                g_new (tensor): gradient at new iterate\n",
    "                t (float): final steplength\n",
    "                ls_step (int): number of backtracks\n",
    "                closure_eval (int): number of closure evaluations\n",
    "                grad_eval (int): number of gradient evaluations\n",
    "                desc_dir (bool): descent direction flag\n",
    "                    True: p_k is descent direction with respect to the line search\n",
    "                    function\n",
    "                    False: p_k is not a descent direction with respect to the line\n",
    "                    search function\n",
    "                fail (bool): failure flag\n",
    "                    True: line search reached maximum number of iterations, failed\n",
    "                    False: line search succeeded\n",
    "\n",
    "        Notes:\n",
    "          . If encountering line search failure in the deterministic setting, one\n",
    "            should try increasing the maximum number of line search steps max_ls.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if options is None:\n",
    "            options = {}\n",
    "        assert len(self.param_groups) == 1\n",
    "\n",
    "        # load parameter options\n",
    "        group = self.param_groups[0]\n",
    "        lr = group['lr']\n",
    "        line_search = group['line_search']\n",
    "        dtype = group['dtype']\n",
    "        debug = group['debug']\n",
    "\n",
    "        # variables cached in state (for tracing)\n",
    "        state = self.state['global_state']\n",
    "        d = state.get('d')\n",
    "        t = state.get('t')\n",
    "        prev_flat_grad = state.get('prev_flat_grad')\n",
    "        Bs = state.get('Bs')\n",
    "\n",
    "        # keep track of nb of iterations\n",
    "        state['n_iter'] += 1\n",
    "\n",
    "        # set search direction\n",
    "        d = p_k\n",
    "\n",
    "        # modify previous gradient\n",
    "        if prev_flat_grad is None:\n",
    "            prev_flat_grad = g_Ok.clone()\n",
    "        else:\n",
    "            prev_flat_grad.copy_(g_Ok)\n",
    "\n",
    "        # set initial step size\n",
    "        t = lr\n",
    "\n",
    "        # closure evaluation counter\n",
    "        closure_eval = 0\n",
    "\n",
    "        if g_Sk is None:\n",
    "            g_Sk = g_Ok.clone()\n",
    "\n",
    "        # perform Armijo backtracking line search\n",
    "        if line_search == 'Armijo':\n",
    "\n",
    "            # load options\n",
    "            if options:\n",
    "                if 'closure' not in options.keys():\n",
    "                    raise(ValueError('closure option not specified.'))\n",
    "                else:\n",
    "                    closure = options['closure']\n",
    "\n",
    "                if 'gtd' not in options.keys():\n",
    "                    gtd = g_Sk.dot(d)\n",
    "                else:\n",
    "                    gtd = options['gtd']\n",
    "\n",
    "                if 'current_loss' not in options.keys():\n",
    "                    F_k = closure()\n",
    "                    closure_eval += 1\n",
    "                else:\n",
    "                    F_k = options['current_loss']\n",
    "\n",
    "                if 'eta' not in options.keys():\n",
    "                    eta = 2\n",
    "                elif options['eta'] <= 0:\n",
    "                    raise(ValueError('Invalid eta; must be positive.'))\n",
    "                else:\n",
    "                    eta = options['eta']\n",
    "\n",
    "                if 'c1' not in options.keys():\n",
    "                    c1 = 1e-4\n",
    "                elif options['c1'] >= 1 or options['c1'] <= 0:\n",
    "                    raise(ValueError('Invalid c1; must be strictly between 0 and 1.'))\n",
    "                else:\n",
    "                    c1 = options['c1']\n",
    "\n",
    "                if 'max_ls' not in options.keys():\n",
    "                    max_ls = 10\n",
    "                elif options['max_ls'] <= 0:\n",
    "                    raise(ValueError('Invalid max_ls; must be positive.'))\n",
    "                else:\n",
    "                    max_ls = options['max_ls']\n",
    "\n",
    "                if 'interpolate' not in options.keys():\n",
    "                    interpolate = True\n",
    "                else:\n",
    "                    interpolate = options['interpolate']\n",
    "\n",
    "                if 'inplace' not in options.keys():\n",
    "                    inplace = True\n",
    "                else:\n",
    "                    inplace = options['inplace']\n",
    "                    \n",
    "                if 'ls_debug' not in options.keys():\n",
    "                    ls_debug = False\n",
    "                else:\n",
    "                    ls_debug = options['ls_debug']\n",
    "\n",
    "            else:\n",
    "                raise(ValueError('Options are not specified; need closure evaluating function.'))\n",
    "\n",
    "            # initialize values\n",
    "            if interpolate:\n",
    "                if torch.cuda.is_available():\n",
    "                    F_prev = torch.tensor(np.nan, dtype=dtype).cuda()\n",
    "                else:\n",
    "                    F_prev = torch.tensor(np.nan, dtype=dtype)\n",
    "\n",
    "            ls_step = 0\n",
    "            t_prev = 0 # old steplength\n",
    "            fail = False # failure flag\n",
    "\n",
    "            # begin print for debug mode\n",
    "            if ls_debug:\n",
    "                print('==================================== Begin Armijo line search ===================================')\n",
    "                print('F(x): %.8e  g*d: %.8e' % (F_k, gtd))\n",
    "\n",
    "            # check if search direction is descent direction\n",
    "            if gtd >= 0:\n",
    "                desc_dir = False\n",
    "                if debug:\n",
    "                    print('Not a descent direction!')\n",
    "            else:\n",
    "                desc_dir = True\n",
    "\n",
    "            # store values if not in-place\n",
    "            if not inplace:\n",
    "                current_params = self._copy_params()\n",
    "\n",
    "            # update and evaluate at new point\n",
    "            self._add_update(t, d)\n",
    "            F_new = closure()\n",
    "            closure_eval += 1\n",
    "\n",
    "            # print info if debugging\n",
    "            if ls_debug:\n",
    "                print('LS Step: %d  t: %.8e  F(x+td): %.8e  F-c1*t*g*d: %.8e  F(x): %.8e'\n",
    "                      % (ls_step, t, F_new, F_k + c1 * t * gtd, F_k))\n",
    "\n",
    "            # check Armijo condition\n",
    "            while F_new > F_k + c1*t*gtd or not is_legal(F_new):\n",
    "\n",
    "                # check if maximum number of iterations reached\n",
    "                if ls_step >= max_ls:\n",
    "                    if inplace:\n",
    "                        self._add_update(-t, d)\n",
    "                    else:\n",
    "                        self._load_params(current_params)\n",
    "\n",
    "                    t = 0\n",
    "                    F_new = closure()\n",
    "                    closure_eval += 1\n",
    "                    fail = True\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # store current steplength\n",
    "                    t_new = t\n",
    "\n",
    "                    # compute new steplength\n",
    "\n",
    "                    # if first step or not interpolating, then multiply by factor\n",
    "                    if ls_step == 0 or not interpolate or not is_legal(F_new):\n",
    "                        t = t/eta\n",
    "\n",
    "                    # if second step, use function value at new point along with \n",
    "                    # gradient and function at current iterate\n",
    "                    elif ls_step == 1 or not is_legal(F_prev):\n",
    "                        t = polyinterp(np.array([[0, F_k.item(), gtd.item()], [t_new, F_new.item(), np.nan]]))\n",
    "\n",
    "                    # otherwise, use function values at new point, previous point,\n",
    "                    # and gradient and function at current iterate\n",
    "                    else:\n",
    "                        t = polyinterp(np.array([[0, F_k.item(), gtd.item()], [t_new, F_new.item(), np.nan], \n",
    "                                                [t_prev, F_prev.item(), np.nan]]))\n",
    "\n",
    "                    # if values are too extreme, adjust t\n",
    "                    if interpolate:\n",
    "                        if t < 1e-3 * t_new:\n",
    "                            t = 1e-3 * t_new\n",
    "                        elif t > 0.6 * t_new:\n",
    "                            t = 0.6 * t_new\n",
    "\n",
    "                        # store old point\n",
    "                        F_prev = F_new\n",
    "                        t_prev = t_new\n",
    "\n",
    "                    # update iterate and reevaluate\n",
    "                    if inplace:\n",
    "                        self._add_update(t - t_new, d)\n",
    "                    else:\n",
    "                        self._load_params(current_params)\n",
    "                        self._add_update(t, d)\n",
    "\n",
    "                    F_new = closure()\n",
    "                    closure_eval += 1\n",
    "                    ls_step += 1 # iterate\n",
    "                    \n",
    "                    # print info if debugging\n",
    "                    if ls_debug:\n",
    "                        print('LS Step: %d  t: %.8e  F(x+td):   %.8e  F-c1*t*g*d: %.8e  F(x): %.8e'\n",
    "                              % (ls_step, t, F_new, F_k + c1 * t * gtd, F_k))\n",
    "\n",
    "            # store Bs\n",
    "            if Bs is None:\n",
    "                Bs = (g_Sk.mul(-t)).clone()\n",
    "            else:\n",
    "                Bs.copy_(g_Sk.mul(-t))\n",
    "                \n",
    "            # print final steplength\n",
    "            if ls_debug:\n",
    "                print('Final Steplength:', t)\n",
    "                print('===================================== End Armijo line search ====================================')\n",
    "\n",
    "            state['d'] = d\n",
    "            state['prev_flat_grad'] = prev_flat_grad\n",
    "            state['t'] = t\n",
    "            state['Bs'] = Bs\n",
    "            state['fail'] = fail\n",
    "\n",
    "            return F_new, t, ls_step, closure_eval, desc_dir, fail\n",
    "\n",
    "        # perform weak Wolfe line search\n",
    "        elif line_search == 'Wolfe':\n",
    "\n",
    "            # load options\n",
    "            if options:\n",
    "                if 'closure' not in options.keys():\n",
    "                    raise(ValueError('closure option not specified.'))\n",
    "                else:\n",
    "                    closure = options['closure']\n",
    "\n",
    "                if 'current_loss' not in options.keys():\n",
    "                    F_k = closure()\n",
    "                    closure_eval += 1\n",
    "                else:\n",
    "                    F_k = options['current_loss']\n",
    "\n",
    "                if 'gtd' not in options.keys():\n",
    "                    gtd = g_Sk.dot(d)\n",
    "                else:\n",
    "                    gtd = options['gtd']\n",
    "\n",
    "                if 'eta' not in options.keys():\n",
    "                    eta = 2\n",
    "                elif options['eta'] <= 1:\n",
    "                    raise(ValueError('Invalid eta; must be greater than 1.'))\n",
    "                else:\n",
    "                    eta = options['eta']\n",
    "\n",
    "                if 'c1' not in options.keys():\n",
    "                    c1 = 1e-4\n",
    "                elif options['c1'] >= 1 or options['c1'] <= 0:\n",
    "                    raise(ValueError('Invalid c1; must be strictly between 0 and 1.'))\n",
    "                else:\n",
    "                    c1 = options['c1']\n",
    "\n",
    "                if 'c2' not in options.keys():\n",
    "                    c2 = 0.9\n",
    "                elif options['c2'] >= 1 or options['c2'] <= 0:\n",
    "                    raise(ValueError('Invalid c2; must be strictly between 0 and 1.'))\n",
    "                elif options['c2'] <= c1:\n",
    "                    raise(ValueError('Invalid c2; must be strictly larger than c1.'))\n",
    "                else:\n",
    "                    c2 = options['c2']\n",
    "\n",
    "                if 'max_ls' not in options.keys():\n",
    "                    max_ls = 10\n",
    "                elif options['max_ls'] <= 0:\n",
    "                    raise(ValueError('Invalid max_ls; must be positive.'))\n",
    "                else:\n",
    "                    max_ls = options['max_ls']\n",
    "\n",
    "                if 'interpolate' not in options.keys():\n",
    "                    interpolate = True\n",
    "                else:\n",
    "                    interpolate = options['interpolate']\n",
    "\n",
    "                if 'inplace' not in options.keys():\n",
    "                    inplace = True\n",
    "                else:\n",
    "                    inplace = options['inplace']\n",
    "                    \n",
    "                if 'ls_debug' not in options.keys():\n",
    "                    ls_debug = False\n",
    "                else:\n",
    "                    ls_debug = options['ls_debug']\n",
    "\n",
    "            else:\n",
    "                raise(ValueError('Options are not specified; need closure evaluating function.'))\n",
    "\n",
    "            # initialize counters\n",
    "            ls_step = 0\n",
    "            grad_eval = 0 # tracks gradient evaluations\n",
    "            t_prev = 0 # old steplength\n",
    "\n",
    "            # initialize bracketing variables and flag\n",
    "            alpha = 0\n",
    "            beta = float('Inf')\n",
    "            fail = False\n",
    "\n",
    "            # initialize values for line search\n",
    "            if(interpolate):\n",
    "                F_a = F_k\n",
    "                g_a = gtd\n",
    "\n",
    "                if(torch.cuda.is_available()):\n",
    "                    F_b = torch.tensor(np.nan, dtype=dtype).cuda()\n",
    "                    g_b = torch.tensor(np.nan, dtype=dtype).cuda()\n",
    "                else:\n",
    "                    F_b = torch.tensor(np.nan, dtype=dtype)\n",
    "                    g_b = torch.tensor(np.nan, dtype=dtype)\n",
    "\n",
    "            # begin print for debug mode\n",
    "            if ls_debug:\n",
    "                print('==================================== Begin Wolfe line search ====================================')\n",
    "                print('F(x): %.8e  g*d: %.8e' % (F_k, gtd))\n",
    "\n",
    "            # check if search direction is descent direction\n",
    "            if gtd >= 0:\n",
    "                desc_dir = False\n",
    "                if debug:\n",
    "                    print('Not a descent direction!')\n",
    "            else:\n",
    "                desc_dir = True\n",
    "\n",
    "            # store values if not in-place\n",
    "            if not inplace:\n",
    "                current_params = self._copy_params()\n",
    "\n",
    "            # update and evaluate at new point\n",
    "            self._add_update(t, d)\n",
    "            F_new = closure()\n",
    "            closure_eval += 1\n",
    "\n",
    "            # main loop\n",
    "            while True:\n",
    "\n",
    "                # check if maximum number of line search steps have been reached\n",
    "                if ls_step >= max_ls:\n",
    "                    if inplace:\n",
    "                        self._add_update(-t, d)\n",
    "                    else:\n",
    "                        self._load_params(current_params)\n",
    "\n",
    "                    t = 0\n",
    "                    F_new = closure()\n",
    "                    F_new.backward()\n",
    "                    g_new = self._gather_flat_grad()\n",
    "                    closure_eval += 1\n",
    "                    grad_eval += 1\n",
    "                    fail = True\n",
    "                    break\n",
    "\n",
    "                # print info if debugging\n",
    "                if ls_debug:\n",
    "                    print('LS Step: %d  t: %.8e  alpha: %.8e  beta: %.8e' \n",
    "                          % (ls_step, t, alpha, beta))\n",
    "                    print('Armijo:  F(x+td): %.8e  F-c1*t*g*d: %.8e  F(x): %.8e'\n",
    "                          % (F_new, F_k + c1 * t * gtd, F_k))\n",
    "\n",
    "                # check Armijo condition\n",
    "                if F_new > F_k + c1 * t * gtd:\n",
    "\n",
    "                    # set upper bound\n",
    "                    beta = t\n",
    "                    t_prev = t\n",
    "\n",
    "                    # update interpolation quantities\n",
    "                    if interpolate:\n",
    "                        F_b = F_new\n",
    "                        if torch.cuda.is_available():\n",
    "                            g_b = torch.tensor(np.nan, dtype=dtype).cuda()\n",
    "                        else:\n",
    "                            g_b = torch.tensor(np.nan, dtype=dtype)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # compute gradient\n",
    "                    F_new.backward()\n",
    "                    g_new = self._gather_flat_grad()\n",
    "                    grad_eval += 1\n",
    "                    gtd_new = g_new.dot(d)\n",
    "                    \n",
    "                    # print info if debugging\n",
    "                    if ls_debug:\n",
    "                        print('Wolfe: g(x+td)*d: %.8e  c2*g*d: %.8e  gtd: %.8e'\n",
    "                              % (gtd_new, c2 * gtd, gtd))\n",
    "\n",
    "                    # check curvature condition\n",
    "                    if gtd_new < c2 * gtd:\n",
    "\n",
    "                        # set lower bound\n",
    "                        alpha = t\n",
    "                        t_prev = t\n",
    "\n",
    "                        # update interpolation quantities\n",
    "                        if interpolate:\n",
    "                            F_a = F_new\n",
    "                            g_a = gtd_new\n",
    "\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                # compute new steplength\n",
    "\n",
    "                # if first step or not interpolating, then bisect or multiply by factor\n",
    "                if not interpolate or not is_legal(F_b):\n",
    "                    if beta == float('Inf'):\n",
    "                        t = eta*t\n",
    "                    else:\n",
    "                        t = (alpha + beta)/2.0\n",
    "\n",
    "                # otherwise interpolate between a and b\n",
    "                else:\n",
    "                    t = polyinterp(np.array([[alpha, F_a.item(), g_a.item()], [beta, F_b.item(), g_b.item()]]))\n",
    "\n",
    "                    # if values are too extreme, adjust t\n",
    "                    if beta == float('Inf'):\n",
    "                        if t > 2 * eta * t_prev:\n",
    "                            t = 2 * eta * t_prev\n",
    "                        elif t < eta * t_prev:\n",
    "                            t = eta * t_prev\n",
    "                    else:\n",
    "                        if t < alpha + 0.2 * (beta - alpha):\n",
    "                            t = alpha + 0.2 * (beta - alpha)\n",
    "                        elif t > (beta - alpha) / 2.0:\n",
    "                            t = (beta - alpha) / 2.0\n",
    "\n",
    "                    # if we obtain nonsensical value from interpolation\n",
    "                    if t <= 0:\n",
    "                        t = (beta - alpha) / 2.0\n",
    "\n",
    "                # update parameters\n",
    "                if inplace:\n",
    "                    self._add_update(t - t_prev, d)\n",
    "                else:\n",
    "                    self._load_params(current_params)\n",
    "                    self._add_update(t, d)\n",
    "\n",
    "                # evaluate closure\n",
    "                F_new = closure()\n",
    "                closure_eval += 1\n",
    "                ls_step += 1\n",
    "\n",
    "            # store Bs\n",
    "            if Bs is None:\n",
    "                Bs = (g_Sk.mul(-t)).clone()\n",
    "            else:\n",
    "                Bs.copy_(g_Sk.mul(-t))\n",
    "                \n",
    "            # print final steplength\n",
    "            if ls_debug:\n",
    "                print('Final Steplength:', t)\n",
    "                print('===================================== End Wolfe line search =====================================')\n",
    "\n",
    "            state['d'] = d\n",
    "            state['prev_flat_grad'] = prev_flat_grad\n",
    "            state['t'] = t\n",
    "            state['Bs'] = Bs\n",
    "            state['fail'] = fail\n",
    "\n",
    "            return F_new, g_new, t, ls_step, closure_eval, grad_eval, desc_dir, fail\n",
    "\n",
    "        else:\n",
    "\n",
    "            # perform update\n",
    "            self._add_update(t, d)\n",
    "\n",
    "            # store Bs\n",
    "            if Bs is None:\n",
    "                Bs = (g_Sk.mul(-t)).clone()\n",
    "            else:\n",
    "                Bs.copy_(g_Sk.mul(-t))\n",
    "\n",
    "            state['d'] = d\n",
    "            state['prev_flat_grad'] = prev_flat_grad\n",
    "            state['t'] = t\n",
    "            state['Bs'] = Bs\n",
    "            state['fail'] = False\n",
    "\n",
    "            return t\n",
    "        \n",
    "    def step(self, p_k, g_Ok, g_Sk=None, options={}):\n",
    "        return self._step(p_k, g_Ok, g_Sk, options)\n",
    "\n",
    "\n",
    "class FullBatchLBFGS(LBFGS):\n",
    "    \"\"\"\n",
    "    Implements full-batch or deterministic L-BFGS algorithm. Compatible with\n",
    "    Powell damping. Can be used when evaluating a deterministic function and\n",
    "    gradient. Wraps the LBFGS optimizer. Performs the two-loop recursion,\n",
    "    updating, and curvature updating in a single step.\n",
    "\n",
    "    Implemented by: Hao-Jun Michael Shi and Dheevatsa Mudigere\n",
    "    Last edited 11/15/18.\n",
    "\n",
    "    Warnings:\n",
    "      . Does not support per-parameter options and parameter groups.\n",
    "      . All parameters have to be on a single device.\n",
    "\n",
    "    Inputs:\n",
    "        lr (float): steplength or learning rate (default: 1)\n",
    "        history_size (int): update history size (default: 10)\n",
    "        line_search (str): designates line search to use (default: 'Wolfe')\n",
    "            Options:\n",
    "                'None': uses steplength designated in algorithm\n",
    "                'Armijo': uses Armijo backtracking line search\n",
    "                'Wolfe': uses Armijo-Wolfe bracketing line search\n",
    "        dtype: data type (default: torch.float)\n",
    "        debug (bool): debugging mode\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1, history_size=10, line_search='Wolfe', \n",
    "                 dtype=torch.float, debug=False):\n",
    "        super(FullBatchLBFGS, self).__init__(params, lr, history_size, line_search, \n",
    "             dtype, debug)\n",
    "\n",
    "    def step(self, options=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        Inputs:\n",
    "            options (dict): contains options for performing line search (default: None)\n",
    "            \n",
    "        General Options:\n",
    "            'eps' (float): constant for curvature pair rejection or damping (default: 1e-2)\n",
    "            'damping' (bool): flag for using Powell damping (default: False)\n",
    "\n",
    "        Options for Armijo backtracking line search:\n",
    "            'closure' (callable): reevaluates model and returns function value\n",
    "            'current_loss' (tensor): objective value at current iterate (default: F(x_k))\n",
    "            'gtd' (tensor): inner product g_Ok'd in line search (default: g_Ok'd)\n",
    "            'eta' (tensor): factor for decreasing steplength > 0 (default: 2)\n",
    "            'c1' (tensor): sufficient decrease constant in (0, 1) (default: 1e-4)\n",
    "            'max_ls' (int): maximum number of line search steps permitted (default: 10)\n",
    "            'interpolate' (bool): flag for using interpolation (default: True)\n",
    "            'inplace' (bool): flag for inplace operations (default: True)\n",
    "            'ls_debug' (bool): debugging mode for line search\n",
    "\n",
    "        Options for Wolfe line search:\n",
    "            'closure' (callable): reevaluates model and returns function value\n",
    "            'current_loss' (tensor): objective value at current iterate (default: F(x_k))\n",
    "            'gtd' (tensor): inner product g_Ok'd in line search (default: g_Ok'd)\n",
    "            'eta' (float): factor for extrapolation (default: 2)\n",
    "            'c1' (float): sufficient decrease constant in (0, 1) (default: 1e-4)\n",
    "            'c2' (float): curvature condition constant in (0, 1) (default: 0.9)\n",
    "            'max_ls' (int): maximum number of line search steps permitted (default: 10)\n",
    "            'interpolate' (bool): flag for using interpolation (default: True)\n",
    "            'inplace' (bool): flag for inplace operations (default: True)\n",
    "            'ls_debug' (bool): debugging mode for line search\n",
    "\n",
    "        Outputs (depends on line search):\n",
    "          . No line search:\n",
    "                t (float): steplength\n",
    "          . Armijo backtracking line search:\n",
    "                F_new (tensor): loss function at new iterate\n",
    "                t (tensor): final steplength\n",
    "                ls_step (int): number of backtracks\n",
    "                closure_eval (int): number of closure evaluations\n",
    "                desc_dir (bool): descent direction flag\n",
    "                    True: p_k is descent direction with respect to the line search\n",
    "                    function\n",
    "                    False: p_k is not a descent direction with respect to the line\n",
    "                    search function\n",
    "                fail (bool): failure flag\n",
    "                    True: line search reached maximum number of iterations, failed\n",
    "                    False: line search succeeded\n",
    "          . Wolfe line search:\n",
    "                F_new (tensor): loss function at new iterate\n",
    "                g_new (tensor): gradient at new iterate\n",
    "                t (float): final steplength\n",
    "                ls_step (int): number of backtracks\n",
    "                closure_eval (int): number of closure evaluations\n",
    "                grad_eval (int): number of gradient evaluations\n",
    "                desc_dir (bool): descent direction flag\n",
    "                    True: p_k is descent direction with respect to the line search\n",
    "                    function\n",
    "                    False: p_k is not a descent direction with respect to the line\n",
    "                    search function\n",
    "                fail (bool): failure flag\n",
    "                    True: line search reached maximum number of iterations, failed\n",
    "                    False: line search succeeded\n",
    "\n",
    "        Notes:\n",
    "          . If encountering line search failure in the deterministic setting, one\n",
    "            should try increasing the maximum number of line search steps max_ls.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # load options for damping and eps\n",
    "        if 'damping' not in options.keys():\n",
    "            damping = False\n",
    "        else:\n",
    "            damping = options['damping']\n",
    "            \n",
    "        if 'eps' not in options.keys():\n",
    "            eps = 1e-2\n",
    "        else:\n",
    "            eps = options['eps']\n",
    "        \n",
    "        # gather gradient\n",
    "        grad = self._gather_flat_grad()\n",
    "        \n",
    "        # update curvature if after 1st iteration\n",
    "        state = self.state['global_state']\n",
    "        if state['n_iter'] > 0:\n",
    "            self.curvature_update(grad, eps, damping)\n",
    "\n",
    "        # compute search direction\n",
    "        p = self.two_loop_recursion(-grad)\n",
    "\n",
    "        # take step\n",
    "        return self._step(p, grad, options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6c4ba-8779-4519-812d-9158e825d1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e295fa-d54e-4df9-b021-6c8faf267946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3d22e-5eff-4a91-91f2-636efd0510c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab2830-e78a-42ad-a1e3-570f93ed4ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a67351d-35c3-4a1c-91dc-d324b9465898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312dd00-3522-4483-b7f7-d4494edbe050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24ab30-1b56-43ac-9ac6-c7cf9d014a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad83e96-7ca9-4500-b403-2ac352d61216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66186cfe-74d9-488c-ab60-1f38b37997cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ff8b3-d8b4-41c9-b3e6-26620fb24bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab7dc0-cd50-4d39-a836-35623657a6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf03275-d579-4ba4-987f-dca704f92766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
